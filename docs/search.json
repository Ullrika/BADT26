[
  {
    "objectID": "pages/PP.html",
    "href": "pages/PP.html",
    "title": "Predictive Performance",
    "section": "",
    "text": "Describe how prior and data influence posterior distributions\n\n\nApply this understanding to interpret posterior predictions across different scenarios with varying priors (flat, informed) and data (sparse, abundant)\nReflect on the ethical and practical implication of prior choices in modeling\n\n\nDescribe the purpose of evaluating predictive performance\n\n\nDescribe why evaluation of predictive performance is necessary for model validation, generalization and avoiding overfitting\nDescribe the difference between in-sample and out-of-sample evaluation of predictive performance\nReflect on the limitations of relying solely on predictive performance for decision making\n\n\nDescribe categories of predictive performance metrics\n\n\nDescribe the key difference between the categories\nDescribe Bayesian predictive measures"
  },
  {
    "objectID": "pages/PP.html#learning-goals",
    "href": "pages/PP.html#learning-goals",
    "title": "Predictive Performance",
    "section": "",
    "text": "Describe how prior and data influence posterior distributions\n\n\nApply this understanding to interpret posterior predictions across different scenarios with varying priors (flat, informed) and data (sparse, abundant)\nReflect on the ethical and practical implication of prior choices in modeling\n\n\nDescribe the purpose of evaluating predictive performance\n\n\nDescribe why evaluation of predictive performance is necessary for model validation, generalization and avoiding overfitting\nDescribe the difference between in-sample and out-of-sample evaluation of predictive performance\nReflect on the limitations of relying solely on predictive performance for decision making\n\n\nDescribe categories of predictive performance metrics\n\n\nDescribe the key difference between the categories\nDescribe Bayesian predictive measures"
  },
  {
    "objectID": "pages/PP.html#the-rationale-for-model-evaluation-and-comparison",
    "href": "pages/PP.html#the-rationale-for-model-evaluation-and-comparison",
    "title": "Predictive Performance",
    "section": "The rationale for model evaluation and comparison",
    "text": "The rationale for model evaluation and comparison\nModel evaluation: how good is this model?\n\nGoodness-of-fit: Is the model good enough (for the data)?\nPredictive performance: Can the model make good predictions for new data?\n\nModel comparison: Is the model better than other models?\nTwo critical issues:\n\nLack of fit\nOverfitting\nGeneralization with context"
  },
  {
    "objectID": "pages/PP.html#overfitting",
    "href": "pages/PP.html#overfitting",
    "title": "Predictive Performance",
    "section": "Overfitting",
    "text": "Overfitting\n\n\n\nBest example of overfitting\n\n\nIn MCMC, overfitting, i.e., having more parameters than needed may cause three things:\n\nThe predictions are too good to be true\nDivergence statistics are bad\nPosteriors for individual parameters have huge dispersion\n\nIdentifiability issue: MCMC can’t tell influence on the likelihood come from which parameter"
  },
  {
    "objectID": "pages/PP.html#predictive-performance-metrics-for-bayesian-models",
    "href": "pages/PP.html#predictive-performance-metrics-for-bayesian-models",
    "title": "Predictive Performance",
    "section": "Predictive performance metrics for Bayesian models",
    "text": "Predictive performance metrics for Bayesian models\nBayesian models have a full posterior distribution already!\nWith sufficient computing power, no reason not to use full predictive distribution.\nExpected log predictive density (elpd)\n\\[\nelpd(y,\\tilde{y}_i) = \\sum^n_{i=1}{\\int{p_t (\\tilde{y}_i)\\log \\ p(\\tilde{y}_i |y)\\ d \\tilde{y}_i}}\n\\]\nelpd can be used for computing Widely-applicable information criterion or leave-one-out cross validation.\nExpansion reads:\nVehtari, A.; Gelman, A.; Gabry, J. Practical Bayesian model evaluation using leave-one-out516 cross-validation and WAIC. Statistics and Computing 2017, 27, 1413–1432"
  },
  {
    "objectID": "pages/PP.html#generalization-with-practical-context",
    "href": "pages/PP.html#generalization-with-practical-context",
    "title": "Predictive Performance",
    "section": "Generalization with practical context",
    "text": "Generalization with practical context\nScope of evaluation: in-sample vs out-of-sample\nA model to predict ice cream consumption based on swimming activity.\nIf the model is trained on survey data by people in Lund in summer, will the predictions apply to people in Malmö winter?\nWill the predictions apply to people in Qatar (in desert) in summer?"
  },
  {
    "objectID": "pages/PP.html#out-of-sample-evaluation",
    "href": "pages/PP.html#out-of-sample-evaluation",
    "title": "Predictive Performance",
    "section": "Out-of-sample evaluation",
    "text": "Out-of-sample evaluation\nCross-validation\n\n\n\nK-fold cross validation\n\n\nTrue remedy to out-of-sample prediction problem is to improve the representativeness of sampling protocol. - Not necessarily related to sample size - Be aware of bias in sampling protocol and reduce the bias"
  },
  {
    "objectID": "pages/PP.html#category-of-predictive-performance-metrics",
    "href": "pages/PP.html#category-of-predictive-performance-metrics",
    "title": "Predictive Performance",
    "section": "Category of predictive performance metrics",
    "text": "Category of predictive performance metrics\n\n\n\n\n\n\n\n\nCategory\nDescription\nExample\n\n\n\n\nCentral tendency\nConsiders ONLY the mean distance between observed and predictive values\nMean Rooted Squared Errors\n\n\nIncomplete uncertainty\nIn addition to central tendency, also considers uncertainty from the spread (variance)\nRanked Probability Score\n\n\nComplete uncertainty\nFull predictive density distribution\nExpected Log Predictive Density"
  },
  {
    "objectID": "pages/exercise_3.html",
    "href": "pages/exercise_3.html",
    "title": "Write your own MCMC sampler",
    "section": "",
    "text": "Background\nMCMC-sampling is an important part of contemporary Bayesian analysis. The participants of this course have different backgrounds, with varying experience of MCMC-sampling. The purpose of this exercise is to let everyone practice in specifying and coding up an MCMC sampler. We are not asking for an advanced model to sample from.\n\n\nTask\n\nSelect a Bayesian model (likelihood and prior) with a limited number of parameters (1 or 2) and data (few data points). If you struggle coming up with a model, you can use the coin-flip example (see below).\nSet up a Metropolis-Hastings algorithm to sample from the posterior\nImplement it in code and run it\nVisualise the MCMC-sampling\nRun it with different choices of priors - from flat to specific\n\n\n\nCoin flip\nYou have a coin and believe it is fair with equal chance to get head or tail. To test your belief, you flipped it for 100 times and got 55 heads and 45 tails.\n\nWrite your Bayesian model including a beta prior and a binomial likelihood\nderive the analytical solution- a conjugate posterior.\nCode a Metropolis algorithm to get the posterior for the parameters.\n\nTips: proposes new values for the probability of heads, calculates the acceptance ratio based on the Beta prior and Binomial likelihood, and records the resulting chain, generate a traceplot.\n\nVisualise your sampling steps and summarize your posterior distribution.\nCompare with the analytical solution.\nUpdate the Metropolis algorithm script so that it reflect the following prior: the coin is heavily biased towards heads.\n\n\n\nCoding demonstration for the coin flip example\nCoin flip script"
  },
  {
    "objectID": "pages/exercise_1.html",
    "href": "pages/exercise_1.html",
    "title": "Probability",
    "section": "",
    "text": "Background\nThere are different interpretations and uses of probability.\nProbability as a mathematical measure is agnostic to the interpretation, i.e. the laws of probability are the same.\n\n\nPurpose\n\nTo understand common interpretations of probability and for what they are used\n\n\n\nContent\n\nExperiment to illustrate the frequency interpretation of probability\nTheoretical probability vs Expected frequency\nSubjective probability\n\n\n\nReferences\nI have used examples and text from the book Teaching probability by Jenny Gage and David Spiegelhalter from 2016, Cambridge University Press.\n\n\nFrequency\nThe experiment is setup as follows:\n\nAssign one student to flip the symmetric coin. You can flip the Antoninus Pius - Bronze Sestertius - Roman Empire using the virtual coin flipper on random.org\nRecord if the outcome is heads or tails.\nAssign another student to throw a six sided dice using the virtual dice roller on random.org\nRecord if the outcome is a number in the range 1 to 5 or a six\nRepeat \\(N=5\\) times\n\nRecord the outcomes in a table\nAnswer the following question:\n\nWhat is the observed frequency of the event “heads followed by a six”?\n\n\n\nExpected frequency\nDiscuss:\n\nIs this a reliable estimate of the expected frequency? If not, what can one do to make it more reliable?\nWhat do you expect the frequency to be if \\(N\\) would be a very large number?\n\n\n\n\n\n\n\nTip\n\n\n\nDefine the events A = “heads” and B = “six”.\nSpecify P(A) and P(B).\nCalculate P(A and B) using the multiplication rule for two independent events.\nDon’t forget to multiply by \\(N\\) to get the expected frequency.\n\n\nRepeat the experiment with \\(N = 100\\) to see what happens when the number of observations grow.\n\n\nChance\nNow let us go back to the step where you specified the probabilities P(A) and P(B). How did you do that? One way to do it is to look at the outcome space, find the outcomes that correspond to the event and divide by the total number of outcomes.\nFor the coin the outcome space is “heads” and “tails”, i.e. n = 2. The event of a getting “heads” can occur in one of the outcomes, i.e. m = 1. Under the assumption that all outcomes are equally likely, the theoretical probability for “heads” is \\(\\frac{m}{n} = \\frac{1}{2}\\).\nFor the dice, the outcome space is 1, 2, 3, 4, 5, and 6, i.e. n = 6. The event of getting a “six” can occur in one way, i.e. m = 1. The theoretical probability for the event “six” is therefore \\(\\frac{1}{6}\\).\n\n\n\n\n\n\nNote\n\n\n\nNotice that theoretical probabilities can only be used in balanced situations such as dice, cards, or lottery tickets where it justified to assume symmetry (equal probability) for all possible outcomes.\n\n\n\n\nRelative frequency\nIf we divide the frequency of an event by the number of trials \\(N\\), we get the relative frequency which is a good estimate of a probability for the event to occur at the next iteration of the same experiment.\nLet \\(m\\) be the number of times the event has occurred. \\(E(\\frac{m}{N})=\\frac{E(m)}{N}=\\frac{N\\cdot P(event)}{N} = P(event)\\)\nRelative frequencies can be used to estimate the probability for an event as long as the observations are equally likely across the full outcome space.\n\n\n\n\n\n\nMake sure N is large\n\n\n\nThe more observations (i.e. larger N) the better estimate.\nThe more extreme event, i.e. very low or high probability of occurring, the more observations are needed.\nBe very skeptical to estimates of probabilities that are either 0 and 1, when the event is possible to occur.\n\n\n\n\nBelief (Personal probability)\nTake one of the thumbtacks provided in the exercise and a cup. Put the thumbtack in the cup, shake and place the cup upside down on a table without revealing the outcome.\n\nWhat outcomes are possible?\n\nFocus on the outcome that the thumbtack in the cup is having its head down with the needle pointing upwards.\n\nLet everyone in the group write down their personal probability of this event as a number between 0 and 1, where 0 means that it is impossible to occur and 1 means that it is certain to occur. Write down first without revealing it to the others, and then share!\n\n\n\n\n\n\n\nCromwell’s rule\n\n\n\nProbabilities 1 (“the event will definitely occur”) or 0 (“the event will definitely not occur”) should be avoided, except when applied to statements that are logically true or false.\n\n\n\nDiscuss if and why the personal probabilities differ in the group\n\nThis is an example of probability as a subjective probability that is purely a personal judgement based on available evidence and assumptions.\nMore evidence ought to result in smaller divergence in judgements. One way to illustrate this is to make some tosses of the thumbtack and let everyone revise their judgement.\n\nDo that!\n\nGiven that the evidence is revealing the outcome, the subjective probabilities held by the students in the group should now be either 1 or 0.\nIn reality, we seldom have such full certainty as in this example. Probabilities are almost inevitably based on judgements and assumptions e.g. about a data generating process.\n\n\n\n\n\n\nA general advice\n\n\n\nProbability can be thought of as an expected frequency. Instead of saying that “the probability of the event is 0.20 (or 20%)”, you can say “out of 100 situations like this, we would expect the event to occur 20 times”.\nBy carefully stating the denominator (reference class), ambiguity about the meaning of probability can be avoided.\nThis advice applies to any of the interpretations.\n\n\n\n\nBelief about a unique event\n\nHow certain are you that it will rain in Lundagård during Lundakarnevalen in May this year?\n\n\n\nBelief about a unique number\nDon’t google this before making your judgement!\n\nWhat is the number of tigers in India?"
  },
  {
    "objectID": "pages/conjugate_models.html",
    "href": "pages/conjugate_models.html",
    "title": "Conjugate models",
    "section": "",
    "text": "We say that \\(p(\\pi)\\) is a conjugate prior for \\(L(\\pi|y)\\) if the posterior,\n\\(p(\\pi|y)\\), is from the same model family as the prior.\nThe prior is conjugate with respect to a particular likelihood function.\nThis property is called “conjugacy” and was introduced by Raiffa & Schlaifer (2000), first edition published in 1961.\nConjugate models are still useful. They are used to calculate probability intervals, for updating categorical nodes in binary Bayesian networks.\nThey are limited to simple Bayesian models.\nRaiffa H, Schlaifer R. 2000. Applied statistical decision theory. Wiley classics library ed. New York: Wiley."
  },
  {
    "objectID": "pages/conjugate_models.html#conjugate-model",
    "href": "pages/conjugate_models.html#conjugate-model",
    "title": "Conjugate models",
    "section": "",
    "text": "We say that \\(p(\\pi)\\) is a conjugate prior for \\(L(\\pi|y)\\) if the posterior,\n\\(p(\\pi|y)\\), is from the same model family as the prior.\nThe prior is conjugate with respect to a particular likelihood function.\nThis property is called “conjugacy” and was introduced by Raiffa & Schlaifer (2000), first edition published in 1961.\nConjugate models are still useful. They are used to calculate probability intervals, for updating categorical nodes in binary Bayesian networks.\nThey are limited to simple Bayesian models.\nRaiffa H, Schlaifer R. 2000. Applied statistical decision theory. Wiley classics library ed. New York: Wiley."
  },
  {
    "objectID": "pages/conjugate_models.html#beta-binomial",
    "href": "pages/conjugate_models.html#beta-binomial",
    "title": "Conjugate models",
    "section": "Beta-Binomial",
    "text": "Beta-Binomial\nObservable: number of successes \\(Y\\) out of \\(N\\) independent trials\nObservations(data): \\(y,n\\) (random sample from \\(Y\\) where \\(N=n\\))\nData generating process: \\(Y|\\pi,N \\sim Bin(N,\\pi)\\)\n\\[p(y|\\pi,n) = \\frac{n!}{y!(n-y)!}=\\pi^y(1-\\pi)^{n-y}\\]\nParameter: \\(\\pi\\)\nLikelihood:\n\\[L(\\pi,y,n) = \\frac{n!}{y!(n-y)!}=\\pi^y(1-\\pi)^{n-y}\\]\nlog likelihood\n\\[l(\\pi,y,n) = \\log L(\\pi,y,n) = \\log n! - \\log y! - \\log (n-y)! + y \\log \\pi + (n-y) \\log (1-\\pi)\\]\nSimplification by dropping constant that do not depend on parameter\n\\(l(\\pi,y,n) \\propto y \\log \\pi + (n-y) \\log (1-\\pi)\\)\nPrior: \\(\\pi \\sim Beta(\\alpha,\\beta)\\)\nHyper-parameters: \\(\\alpha\\), \\(\\beta\\)\nPosterior:: \\(\\pi \\sim Beta(\\alpha+y,\\beta+n-y)\\)\n\nImpact on posterior from prior and data\n\n\n\n\n\n\n\n\n\n\n\nReparameterisation\nData generating process: \\(Y|\\pi,N \\sim Bin(N,\\pi)\\)\nLet us look at an alternative parameterisation of the beta distribution\nLet \\(\\alpha=ts\\) and \\(\\beta=(1-t)s\\)\nThe new parameters \\(t\\) and \\(s\\) can be seen as expected relative frequency and “sample size”, respectively.\nPrior: \\(\\pi \\sim Beta(ts,(1-t)s)\\)\nHyper-parameters: \\(t\\), \\(s\\)\nPosterior: \\(\\pi|y,n \\sim Beta(ts+y,(1-t)s+n-y)\\)\n\n\nBayesian learning - Sequential updating\nBayesian inference can be done sequentially, by using the posterior in a previous step as prior in the next step\nPrior step 1: \\(\\pi|s,t \\sim Beta(ts,(1-t)s)\\)\nPosterior step 1: \\(\\pi|y_1,n_1,s_1,t_1 \\sim Beta(t_1s_1+y_1,(1-t_1)s_1+n_1-y_1)\\)\nPosterior expected relative frequency is\n\\[\\frac{t_1s_1+y_1}{t_1s_1+y_1+(1-t_1)s_1+n_1-y_1}=\\frac{t_1s_1+y_1}{s_1+n_1}\\]\nPrior step 2: \\(\\pi|s_2,t_2 \\sim Beta(t_2s_2,(1-t_2)s_2)\\)\nHyperparameters are the expected relative frequency \\(t_2=\\frac{t_1s_1+y_1}{s_1+n_1}\\) and “sample size” \\(s_2 = s_1+n_1\\)\nPosterior step 2: \\(\\pi|y_2,n_2,s_2,t_2 \\sim Beta(t_2s_2+y_2,(1-t_2)s_2+n_2-y_2)\\)\nHyperparameters for step 3 are the expected relative frequency \\(t_3=\\frac{t_2s_2+y_2}{s_2+n_2}=\\frac{t_1s_1 + y_1 + y_2}{s_1+n_1+n_2}\\) and “sample size” \\(s_3 = s_2+n_2=s_1+n_1+n_2\\)\nThis also demonstrates the property of data-order invariance which states that if data is conditionally independent on the model, the order of updating has no effect on the final posterior.\n\n\nParametric inference\nIs it possible to test hypothesis in Bayesian analysis?\n\nBayes factor\nBayesian p-value\nBayesian confidence interval\nBayesian model selection\n\nUsing observed data to choose between two probabilistic models, \\(M_0\\) and \\(M_1\\).\n\\[\\underbrace{\\frac{p(M_1|data)}{p(M_0|data)}}_{\\text{posterior ratio}}=\\underbrace{\\frac{p(M_1)}{p(M_0)}}_{\\text{prior ratio}}\\underbrace{\\frac{p(data|M_1)}{p(data|M_0)}}_{\\text{bayes factor}}\\]\nhttps://www.statlect.com/fundamentals-of-statistics/posterior-odds-ratio\nUsing observed data to choose between two probabilistic models, \\(M_0\\) and \\(M_1\\) that differ in complexity. For example, consider teh binomial model: \\(M_0\\) could be that the parameter \\(\\pi\\) takes a specific value \\(\\pi_0\\), whereas \\(M_1\\) is that it can be any value in the interval \\([0,1]\\).\nThe probability for data under \\(M_0\\), \\(p(data|M_0)\\), is found by using \\(\\pi=\\pi_0\\) in the probabilistic model for data.\nThe probability for data under \\(M_0\\), \\(p(data|M_1)\\) is found by specifying a prior for \\(\\pi\\), do Bayesian updating, and use the posterior \\(\\pi|data\\) to calcualte the expected probability for data under \\(M_1\\)\n\\[p(data|M_1) = \\int_\\infty^\\infty p(data|\\theta,M_1)p(\\theta|M_1)d\\theta\\]"
  },
  {
    "objectID": "pages/conjugate_models.html#conjugate-models-and-the-exponential-family",
    "href": "pages/conjugate_models.html#conjugate-models-and-the-exponential-family",
    "title": "Conjugate models",
    "section": "Conjugate models and the exponential family",
    "text": "Conjugate models and the exponential family\nAnalytic results for the posterior distribution can always be obtained for a class of distributions known as exponential family distributions, provided that conjugate priors are used.\nExponential family distributions can be written in the form\n\\[p(\\mathbf{y}|\\mathbf{\\eta})=f(\\mathbf{y})\\exp \\left[\\mathbf{\\eta}^T\\mathbf{s(y)} + \\psi(\\mathbf{\\eta})\\right]\\] where \\(\\mathbf{\\eta}\\) is a vector of natural parameters, \\(f(\\mathbf{y})\\) is an arbitrary function that depends only on \\(\\mathbf{y}\\), \\(\\mathbf{s(y)}\\) is a vector containing the sufficient statistics for the data \\(\\mathbf{y}\\), and \\(\\psi(\\mathbf{\\eta})\\) is the logarithm of the normalizing constant.\nFor example\n\\(\\eta = \\log \\frac{\\theta}{1-\\theta}\\)\n\\(\\psi(\\eta) = \\log (1+\\exp(\\eta))=-\\log (1-\\theta)\\)\nFor any exponential family distribution, there is a corresponding family of conjugate priors with \\(p(\\mathbf{\\eta}|\\mathbf{y}) \\propto \\exp \\left[ \\mathbf{\\eta}^T\\nu + \\lambda \\psi(\\mathbf{\\eta})\\right]\\).\nConjugacy can be demonstrated by observing that the posterior is given by\n\\(p(\\mathbf{\\eta}|\\mathbf{y}) \\propto p(\\mathbf{y}|\\mathbf{\\eta})p(\\mathbf{\\eta})\\)\n\nNormal-Normal conjugate model\nObservable: \\(Y\\)\nObservations(data): \\(\\mathbf{y}=(y_1,\\ldots,y_n)\\) (random sample from \\(Y\\))\nData generating process: \\(Y|\\mu,\\sigma \\sim N(\\mu,\\sigma)\\)\n\\[p(\\mathbf{y}|\\mu,\\sigma) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp \\left[-\\frac{(y_i-\\mu)^2}{2\\sigma^2} \\right]\\]\nParameters: \\(\\mu\\), \\(\\sigma\\) (we assume \\(\\sigma\\) is known)\nLikelihood:\n\\[L(\\mu,\\mathbf{y}) \\propto \\prod \\exp \\left[-\\frac{(y_i-\\mu)^2}{2\\sigma^2} \\right] = \\exp \\left[-\\frac{\\sum(y_i-\\mu)^2}{2\\sigma^2} \\right] = \\exp \\left[-\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n} \\right]\\]\nlog likelihood\n\\[l(\\mu,\\mathbf{y}) = \\log L(\\mu,\\mathbf{y}) \\propto -\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}\\]\nPrior:\n\\[\\mu|\\sigma \\sim N(\\mu_0,\\frac{\\sigma}{\\sqrt{k}})\\]\nHyper-parameters: \\(\\mu_0\\), \\(k\\)\nLet \\(\\bar{y}=\\frac{1}{n}\\sum_{i=1}^n y_i\\) be the sample mean and \\(s^2 = \\frac{1}{n-1}\\sum_{i=1}^n (y_i-\\bar{y})^2\\) be the sample variance.\nPosterior:\n\\[\\mu|\\sigma,\\mathbf{y} \\sim N(\\frac{k\\mu_0+n\\bar{y}}{k+n},\\frac{\\sigma}{\\sqrt{(k+n)}})\\]\n\n\n\nGamma-Normal conjugate model\nObservable: \\(Y\\)\nObservations(data): \\(\\mathbf{y}=(y_1,\\ldots,y_n)\\) (random sample from \\(Y\\))\nData generating process: \\(Y|\\mu,\\sigma \\sim N(\\mu,\\sigma)\\)\n\\[p(\\mathbf{y}|\\mu,\\sigma) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp \\left[-\\frac{(y_i-\\mu)^2}{2\\sigma^2} \\right]\\]\nParameters: \\(\\mu\\), \\(\\sigma\\)\nLikelihood:\n\\[L(\\mu,\\sigma,\\mathbf{y}) = \\prod \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp \\left[-\\frac{(y_i-\\mu)^2}{2\\sigma^2} \\right] = \\left(\\frac{1}{\\sqrt{2\\pi\\sigma}}\\right)^n\\exp   \\left[-\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n} \\right]\\]\nlog likelihood\n\\[l(\\mu,\\sigma,\\mathbf{y}) = \\log L(\\mu,\\sigma,\\mathbf{y}) =-\\frac{n}{2}\\log (\\pi\\sigma) -\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}\\]\nPrior:\n\\[\\mu|\\sigma \\sim N(\\mu_0,\\frac{\\sigma}{\\sqrt{k}})\\]\n\\[\\frac{1}{\\sigma^2} \\sim \\Gamma (\\alpha_0,\\beta_0)\\]\nHyper-parameters: \\(\\mu_0\\), \\(k\\), \\(\\alpha\\), \\(\\beta\\)\nPosterior:\n\\[\\mu|\\sigma,\\mathbf{y} \\sim N(\\frac{k\\mu_0+n\\bar{y}}{k+n},\\frac{\\sigma}{\\sqrt{(k+n)}})\\]\n\\[\\frac{1}{\\sigma^2}|\\mathbf{y} \\sim \\Gamma (\\alpha_0+\\frac{n}{2},\\beta_0+\\frac{s^2(n-1)}{2}+\\frac{nk}{n+k}\\frac{(\\bar{y}-\\mu_0)^2}{2})\\]\n\n\n\nList of conjugate models\nhttps://en.wikipedia.org/wiki/Conjugate_prior"
  },
  {
    "objectID": "pages/conjugate_models.html#example-from-bayesian-networks",
    "href": "pages/conjugate_models.html#example-from-bayesian-networks",
    "title": "Conjugate models",
    "section": "Example from Bayesian Networks",
    "text": "Example from Bayesian Networks\nBayesian Parameter Estimation in Bayesian Networks (section 17.4 in Koller and Friedman 2009).\nA Bayesian Network can be understood as a probability distribution for data that allows specification of a likelihood. BNs were originally developed for categorical or binary nodes linked with edges into network.\nThe concept was expanded for continuous normally distributed nodes, referred to as Gaussian Networks.\nInference in these networks are of two types:\n\nPredictive inference: calculation of the probability of query variables (a subset of variables in the network) given evidence defined by an instantiation of a subset of variables in the network.\n\n\\[p(\\mathbf{Y}|\\mathbf{E}=\\mathbf{e})\\]\n\nParametric inference: Inference of the parameters in a network. This can be to estimate Conditional Probability Tables (CPTs) or expected values and variances in Gaussian Networks.\n\nParametric inference can be done using maximum likelihood estimation.\nTo perform Bayesian parameter estimation of a Bayesian Network, one has to specify a joint probability distribution of the unknown parameters and observables. Koller and Friedman (2009) refers to it as adding a meta-network for learning. Assumes global parameter independence, i.e. priors for parameters do not depend on each other. This allows taking expectations over parameters when making predictions independently and then combine the results when making predictions.\n\nKoller, D., & Friedman, N. (2009). Probabilistic graphical models: principles and techniques. MIT press. PDF\nDemonstration of implementation of priors in Bayesian Networks\nBayesFusion\nhttps://repo.bayesfusion.com/bayesbox.html"
  },
  {
    "objectID": "pages/conjugate_models.html#monte-carlo-simulation",
    "href": "pages/conjugate_models.html#monte-carlo-simulation",
    "title": "Conjugate models",
    "section": "Monte Carlo simulation",
    "text": "Monte Carlo simulation\nConsider the expected value of a function \\(g\\) of the random variable \\(\\theta\\)\n\\[E(g(\\theta)) = \\int_{-\\infty}^{\\infty} g(\\theta)f(\\theta)d\\theta\\]\nAt best, one can use various approximations of the function to derive the target quantity.\nWhen the number of variables increase, it quickly becomes demanding to calculate the expected value\n\\[E(g(\\theta_1,\\theta_2,\\ldots)) = \\int_{-\\infty}^{\\infty} g(\\theta_1,\\theta_2,\\ldots)f(\\theta_1,\\theta_2,\\ldots)d\\theta_1d\\theta_2\\cdots\\]\nMonte Carlo simulation is a numerical method to approximate functions of random variables or processes.\nMonte Carlo approximation works provided that there exists a finite expected value and variance of the function, i.e. that \\(E(|g(\\mathbf{\\theta})|) &lt; \\infty\\) and \\(V(g(\\mathbf{\\theta})) &lt; \\infty\\)\n\n\n\n\n\n\nSome useful theorems\n\n\n\n\nThe weak law of large numbers\nIf \\(X_1,\\ldots\\) are independent and identically distributed random variables with the same expected value \\(\\mu\\), then the average of the random variables converges to the expected value as the number of variables \\(n\\) goes towards infinity:\n\\[\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i \\overset{p}{\\rightarrow} \\mu\\]\nConvergence in probability \\(p\\) is the same thing to say that the average converges to the value \\(\\mu\\) with probability 1.\n\n\nThe strong law of large numbers\nLet \\(X_1,\\ldots\\) be a sequence of independent and identically distributed random variables where the expected value of the absolute random variable is finite, i.e. \\(E(|X_1|) &lt; \\infty\\). Let \\(E(X_1)=\\mu\\), then the average of the random variables converges to the expected value as the number of variables \\(n\\) goes towards infinity:\n\\[\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i \\overset{a.s.}{\\rightarrow} \\mu\\]\n\\(a.s.\\) means “almost surely”, and is a stronger type of convergence than convergence in probability.\n\n\n\nReflection from Kadane\n\nConjugate analysis is neat mathematically when it works. However, the slightest deviation in the specification of the likelihood or prior would destroy the property of conjugacy. Consequently, these results are interesting but far from a usable platform from which to do analyses.\n\n\nSimilarly, large sample theory is nice, but gives little guidance on how large a sample is required for large sample theory to yield good approximations. Since Bayesian analyses can and do deal with small samples as well as large ones (indeed Bayesians can gracefully make decisions with no data at all, relying on their prior), large sample theory is also quite limited in scope.\n\n\nBecause of these limitations, Bayesians now rely heavily on computational methods to find posterior distributions\n\nKadane, J. B. (2020). Principles of uncertainty 2nd. Chapman and Hall/CRC. PDF"
  },
  {
    "objectID": "pages/conjugate_models.html#reflection-from-kadane",
    "href": "pages/conjugate_models.html#reflection-from-kadane",
    "title": "Conjugate models",
    "section": "Reflection from Kadane",
    "text": "Reflection from Kadane\n\nConjugate analysis is neat mathematically when it works. However, the slightest deviation in the specification of the likelihood or prior would destroy the property of conjugacy. Consequently, these results are interesting but far from a usable platform from which to do analyses.\n\n\nSimilarly, large sample theory is nice, but gives little guidance on how large a sample is required for large sample theory to yield good approximations. Since Bayesian analyses can and do deal with small samples as well as large ones (indeed Bayesians can gracefully make decisions with no data at all, relying on their prior), large sample theory is also quite limited in scope.\n\n\nBecause of these limitations, Bayesians now rely heavily on computational methods to find posterior distributions\n\nKadane, J. B. (2020). Principles of uncertainty 2nd. Chapman and Hall/CRC. PDF"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BADT26",
    "section": "",
    "text": "First meeting 2-3 Feb\nDay 1 Monday, 2 Feb 2026 (12-16)\nLundmarkssalen Astronomihuset\n12.15 Course introduction\n12.25 Lecture with non-computer exercises: Bayesian inference and subjective probability\nReading: BR* (Chapters 1 and 2) and DBDA* (Chapter 2, 4 and 5)\nExercise 1: Probability\n13.00 Break\n13.15 Lecture about conjugate models\nReadings: BR* (Chapters 3 and 5) and DBDA* (Chapters 6)\n14.00 Break\n14.15 Exercise 2: Conjugate models\n15.00 Break\n15.15 Lecture on Bayesian analysis using MCMC\nExercise 3. Write your own MCMC sampler\nDay 2 Tuesday, 3 Feb 09.00 - 14.00\nPufendorf Institute for Advanced Studies\n09.15 Bayesian analysis using MCMC\nReading: BR* (Chapters 6, 7, 8) and DBDA* (Chapter 7)\nExercise 3. Write your own MCMC sampler\n10.00 Short lecture Introduction to software for MCMC sampling (Zheng)\nExercise 4. Get started with a software for MCMC sampling\n10.30 Lecture Predictive performance in Bayesian inference\n11.00 Break\n11.15 Lecture Generalised Linear Regression models with exercises\nReading: BR* (Chapters 9, 10, 11) and DBDA* (Chapter 15)\nExercise 5. Specifying models through graphs\n12-13 Lunch\n13.15 Exercise 6. Specify and run GLMs in MCMC samplers.\n14.15 Lecture on Decision theory Reading: 1* and 2*\n\n\nSecond meeting 24-25 Feb\nMaterial for second meeting to come"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html",
    "href": "pages/Bayesian_inference_subjective_probability.html",
    "title": "Bayesian inference and subjective probability",
    "section": "",
    "text": "Reading: BR* (Chapters 1 and 2) and DBDA* (Chapter 2, 4 and 5)\nContent: Probability, statistical inference, likelihood, priors, Bayes rule, posterior"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#content",
    "href": "pages/Bayesian_inference_subjective_probability.html#content",
    "title": "Bayesian inference and subjective probability",
    "section": "",
    "text": "Reading: BR* (Chapters 1 and 2) and DBDA* (Chapter 2, 4 and 5)\nContent: Probability, statistical inference, likelihood, priors, Bayes rule, posterior"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#classical-probability",
    "href": "pages/Bayesian_inference_subjective_probability.html#classical-probability",
    "title": "Bayesian inference and subjective probability",
    "section": "Classical probability",
    "text": "Classical probability\nConditional probability\n\nIf of the two subsequent events, the probability of the 1st be \\(a/N\\) and the probability of both together be \\(P/N\\), then the probability of the 2nd on the supposition the 1st happens is \\(P/a\\). \\(P(B|A)=P(A \\& B)/P(A)\\)\n\nBayes, hesitantly, concluded that time does not distinguish between the events and therefore that the relationship between \\(A\\) and \\(B\\) is not necessarily causal. \\(P(A|B)P(B)=P(B|A)P(A)\\)\nLaplace’s law of succession\n\nIf an urn contains an infinity of white and black tickets in an unknown ratio, and if p + q tickets are drawn of which p are white and q are black, we ask the probability that in drawing a new ticket from this urn it will be white.\n\nLaplace suggested to replace a single urn of unknown constitution with an infinity of urns of known constitution \\[\\frac{\\int_0^1x^{p+1}(1-x)^qdx}{\\int_0^1x^{p}(1-x)^qdx}=\\frac{p+1}{p+q+2}\\]"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#frequentist-probability",
    "href": "pages/Bayesian_inference_subjective_probability.html#frequentist-probability",
    "title": "Bayesian inference and subjective probability",
    "section": "Frequentist probability",
    "text": "Frequentist probability\nBernoulli (1655-1705) in Ars Conjectandi:\nIf you take a large enough sample, you can be sure, that the proportion of white pebbles you observe in the sample is close to the proportion in the urn (Law of Large Numbers).\n\n“The sample ratio is close to a given urn ratio with a high probability” vs “The urn ratio is close to a given sample ratio with high probability.”\n\n\nFascination with the normal curve and deviations from average (Adolphe Quetelet)\nGalton’s natural selection and eugenics. Reversion (or regression) towards mediocrity in hereditary studies\nPearson - numerical measure of normality \\(\\chi^2\\).\nYoung genius Fischer. Break-off. Animosity and hostility. Fischer’s continuous war with Egon Pearson and Jerzy Nyman.\n\n[1] Clayton (2021) [2] Acree (2021)"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#logical-probability",
    "href": "pages/Bayesian_inference_subjective_probability.html#logical-probability",
    "title": "Bayesian inference and subjective probability",
    "section": "Logical probability",
    "text": "Logical probability\n\nInference is an extension of Boolean algebra with an implication operator \\(A\\implies B\\) (“A implies B”).\nImplication does not assert that either \\(A\\) or \\(B\\) is true, but merely that \\(A\\overline{B}\\) is FALSE, i.e. that \\((\\overline{A}+B)\\) is TRUE. Also can be expressed as \\(A=AB\\): propositions \\(A\\) and \\(AB\\) have the same truth value.\n\nDesiderata for plausibility reasoning:\n\nRepresentation of degrees of plausibility by real numbers;\nQualitative correspondence with common sense;\nConsistency:\n\nIf a conclusion can be reasoned out in more than one way, then every possible way must lead to the same result\nThe robot always takes into account all of the evidence it has relevant to a question. […] the robot is completely nonideological.\nThe robot always represents equivalent states of knowledge by equivalent plausibility assignments.\n\n\nRandomization does not change the state of the world. It alters our knowledge. Mind-projection fallacy.\n[1] Jaynes(2003)"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#logical-probability-1",
    "href": "pages/Bayesian_inference_subjective_probability.html#logical-probability-1",
    "title": "Bayesian inference and subjective probability",
    "section": "Logical probability",
    "text": "Logical probability\n\nRules of plausibility reasoning\n\nThe product rule\n\n\\[p(AB|C)=p(A|C)p(B|AC)=p(B|C)p(A|BC)\\]\n\nThe sum rule\n\n\\[p(A|B)+p(\\overline{A}|B)=1\\]\n\\[p(A+B|C)=p(A|C)+p(B|C)-p(AB|C)\\]\nInterpretation of plausibility\n\\(A \\implies B\\)\n\n\\(B\\) is true, therefore \\(A\\) becomes more plausible\n\\(A\\) is false, therefore \\(B\\) becomes less plausible\n\n[1] Jaynes (2003)"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#subjectivist-probability",
    "href": "pages/Bayesian_inference_subjective_probability.html#subjectivist-probability",
    "title": "Bayesian inference and subjective probability",
    "section": "Subjectivist probability",
    "text": "Subjectivist probability\nBeliefs without actions are abstract. Probabilities can be understood only in the context of an agent (someone making a decision or doing reasoning).\n\nBruno de Finetti (1906-1985)\n\n“PROBABILITY DOES NOT EXIST!”\nInterpretation of probability as personal attitude to uncertainty is inseparable from willingness to take risk\nUnexperienced uncertainty (nothing at stake) is not a real uncertainty\nUncertainty can only be observed (and probabilities can be extracted) from betting behavior\n\n\n\nFrank Ramsey (1903-1930)[1]\n\nProbabilities are subjective. Both prior beliefs and previously experienced frequencies are relevant for decision\nBeliefs can be separated from preferences through the definition of “ethically neutral proposition” (uninfluenced decision)\n\n[1]N-E Sahlin"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#knightian-uncertainty",
    "href": "pages/Bayesian_inference_subjective_probability.html#knightian-uncertainty",
    "title": "Bayesian inference and subjective probability",
    "section": "Knightian uncertainty",
    "text": "Knightian uncertainty\nKnight (1921):\n\nrisk - inherent randomness in the world described by probability\nuncertainty - lack of knowledge. “Uncertainty occurs when we cannot assign values to the probability”\n\nBayes and Knight does not combine!\nIntroduce uncertainty about probabilities e.g. \nImprecise probability theory:\n\nWhat to do when one can not assign a single probability number?\nProbability represented by bounds without any distribution assigned to them (NOT uniform!)\n\nRobust Bayesian approach gives imprecise probabilities\n\nSets of priors or sets of likelihoods\nFind bounds of probabilities when summarising quantities of interest\n\nRelax the strict interpretation of Knight (he admitted that probability can describe uncertainty when there is enough basis to make judgements or Bayesian inferece)\n\nAvoid conflating probabilities defining risk with probabilities expressing uncertainty about risk"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#time-to-reflect",
    "href": "pages/Bayesian_inference_subjective_probability.html#time-to-reflect",
    "title": "Bayesian inference and subjective probability",
    "section": "Time to reflect",
    "text": "Time to reflect\n\nHow can different interpretations of probability affect a scientific discussion or knowledge generating process?\nWhich perspectives on probability have you encountered in you research experience?"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#likelihood",
    "href": "pages/Bayesian_inference_subjective_probability.html#likelihood",
    "title": "Bayesian inference and subjective probability",
    "section": "Likelihood",
    "text": "Likelihood\n\\(p(data|\\text{parameters})\\)\n\nParameters as fixed and data as variable\nData as fixed and parameter as uncertain"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#steps-of-a-bayesian-data-analysis",
    "href": "pages/Bayesian_inference_subjective_probability.html#steps-of-a-bayesian-data-analysis",
    "title": "Bayesian inference and subjective probability",
    "section": "Steps of a Bayesian data analysis",
    "text": "Steps of a Bayesian data analysis\n\nIdentify data relevant to the research question (question/model-first)\nDefine a probabilistic data generating model (linking data to question/model, needed to derive the likelihood)\nSpecify prior for parameters within the model\nUse Bayesian inference to re-allocate credibility across parameter values. Interpret the posterior with respect to the validity of the model.\nCheck that the posterior predictions mimic the data with reasonable accuracy (i.e. make posterior predictive check)"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#parametric-inference-parameter-estimation",
    "href": "pages/Bayesian_inference_subjective_probability.html#parametric-inference-parameter-estimation",
    "title": "Bayesian inference and subjective probability",
    "section": "Parametric inference (parameter estimation)",
    "text": "Parametric inference (parameter estimation)\nInference about parameters are made by summarising the posterior for the quantity of interest.\n\nPosterior mean and variance\nPosterior mode\nPosterior probability interval\nPosterior quantiles (percentiles)\nPropagation of posterior uncertainty into quantities derived from parameters \\(g(\\theta)\\)\n\n\nBayesian p-value\nSometimes, analysts derive a Bayesian “p-value” which is the posterior probability of a null hypothesis. If this probability is small, then the null hypothesis can be rejected. Note that this is a pragmatic approach adopting frequentist terminology and not part of Bayesian theory.\nFor example, we specify the following hypotheses:\n\\(H_0: \\theta \\leq 0\\) against \\(H_1: \\theta &gt; 0\\)\nThe Bayesian p-value is then \\(\\text{Bayesian p-value}=\\int_{-\\infty}^0 p(\\theta|data)d\\theta\\) where \\(p(\\theta|data)\\) denotes the posterior density."
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#predictive-inference-predicting-new-observations",
    "href": "pages/Bayesian_inference_subjective_probability.html#predictive-inference-predicting-new-observations",
    "title": "Bayesian inference and subjective probability",
    "section": "Predictive inference (predicting new observations)",
    "text": "Predictive inference (predicting new observations)\n\nPosterior predictive\nData validation (predictive performance)\nForecasting, classification, etc"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#bayesian-vs-frequentist",
    "href": "pages/Bayesian_inference_subjective_probability.html#bayesian-vs-frequentist",
    "title": "Bayesian inference and subjective probability",
    "section": "Bayesian vs Frequentist",
    "text": "Bayesian vs Frequentist\nThis section is inspired by Efron and Hastie’s book Computer age statistical inference - algorithms, evidence, and data science\n\nBayesian inference requires a prior distribution, and the choice of prior is therefore important and sometimes challenging.\nFrequentism replaces the choice of a prior with the choice of a method or algorithm designed for the quantity of interest.\nBayesian inference answers all possible questions at once.\nFrequentism requires different methods/algorithms for different questions.\nBayesian inference is open for sequential updating, e.g. when data are to be integrated to the model over time.\n\n\nThe authors states that “Computer-age statistical inference at its most successful combines elements of the two philosophies”"
  },
  {
    "objectID": "pages/course_intro.html",
    "href": "pages/course_intro.html",
    "title": "Course introduction",
    "section": "",
    "text": "A PhD course in Bayesian analysis for participants that are not from maths\nA PhD course that brings up the link between Bayesian inference and Decision theory\nA possibility to discuss, praise and challenge Bayesian thinking\nAn introduction to Bayesian analysis to get started or get more experience\n\nBayesian analysis: Bayesian statistics, Bayesian inference, Bayesian data analysis, Bayesian modelling, Bayesian computation, Bayesian networks, Bayesian emulation, Bayesian evidence synthesis\nDecision theory: Bayesian decision theory, Bayesian hypothesis testing, Bayesian learning, decision making under uncertainty, evidence-based decision making, communicating uncertainty, uncertainty analysis in assessments, weight of evidence approaches\n\nSummer school 2015, PhD course spring 2018, PhD course online spring 2022, PhD course physical 2026\n\nBayes@Lund web page\nBayes@Lund Youtube Channel"
  },
  {
    "objectID": "pages/course_intro.html#why-this-course",
    "href": "pages/course_intro.html#why-this-course",
    "title": "Course introduction",
    "section": "",
    "text": "A PhD course in Bayesian analysis for participants that are not from maths\nA PhD course that brings up the link between Bayesian inference and Decision theory\nA possibility to discuss, praise and challenge Bayesian thinking\nAn introduction to Bayesian analysis to get started or get more experience\n\nBayesian analysis: Bayesian statistics, Bayesian inference, Bayesian data analysis, Bayesian modelling, Bayesian computation, Bayesian networks, Bayesian emulation, Bayesian evidence synthesis\nDecision theory: Bayesian decision theory, Bayesian hypothesis testing, Bayesian learning, decision making under uncertainty, evidence-based decision making, communicating uncertainty, uncertainty analysis in assessments, weight of evidence approaches\n\nSummer school 2015, PhD course spring 2018, PhD course online spring 2022, PhD course physical 2026\n\nBayes@Lund web page\nBayes@Lund Youtube Channel"
  },
  {
    "objectID": "pages/course_intro.html#goals",
    "href": "pages/course_intro.html#goals",
    "title": "Course introduction",
    "section": "Goals",
    "text": "Goals\nContent:\nBayesian analysis, Discrete Bayesian Belief Networks, Hierarchical modelling, Continuous Bayesian Belief Networks\nProbabilistic uncertainty analysis, Non-probabilistic methods for uncertainty analysis, Scientific principles to quantify uncertainty\nBayesian Decision Theory, Principles of cautious decision making"
  },
  {
    "objectID": "pages/course_intro.html#material-and-content",
    "href": "pages/course_intro.html#material-and-content",
    "title": "Course introduction",
    "section": "Material and content",
    "text": "Material and content\nTwo books\nBR - Alicia A. Johnson, Miles Ott, Mine Dogucu Bayes Rules\nDBDA - John K. Kruschke Doing Bayesian Data Analysis\nAdditional material: lecture notes and exercises available and updated during the course on this git web page"
  },
  {
    "objectID": "pages/course_intro.html#assessment",
    "href": "pages/course_intro.html#assessment",
    "title": "Course introduction",
    "section": "Assessment",
    "text": "Assessment\nAssessment is based on student activities in practical exercises and seminars, and on the written project report.\n\nPresence at the two physical meetings (let us know if you cannot attend in advance)\nActive participation in literature seminars\nCompleted individual report"
  },
  {
    "objectID": "pages/course_intro.html#literature-seminar",
    "href": "pages/course_intro.html#literature-seminar",
    "title": "Course introduction",
    "section": "Literature seminar",
    "text": "Literature seminar\n\nLearning goals\n\nDigest a Bayesian decision analysis for a concrete problem\nPractice to identify sources of uncertainty in an assessment\nBe able to give examples of principles to quantify and treat uncertainty in a Bayesian analysis\nBe able to give an account of science theoretic arguments behind principles to quantify and treat uncertainty in knowledge production and decision making\nReflect on the limitations and justification of Bayesian principles and subjective probability to produce scientific advice or decision support\nPractice collaboration and presentation in an interdisciplinary context\n\n\n\nInstructions\nThe literature seminar is constructed around three themes.\n\nBefore the seminar\n\nDownload the literature. You have been placed in a group (A-C). You are to read the three papers assigned to your group. Skim through the other papers. Look at the questions for your group.\n\nDuring the seminar\n\nTogether with your group, prepare and give a presentation of the three papers (try to keep it short &lt; 8 min per paper). Structure the presentation around the answers to the questions under that theme.\n\n\nTheme 1: The Bayesian analysis combined with decision making\nGroup A. Augustynczik, A. L. et al. Productivity of Fagus sylvatica under climate change–A Bayesian analysis of risk and uncertainty using the model 3-PG. Forest Ecology and Management 401, 192–206 (2017). link to paper\nGroup B. Spiegelhalter, D. J. & Best, N. G. Bayesian approaches to multiple sources of evidence and uncertainty in complex cost-effectiveness modelling. Statist. Med. 22, 3687–3709 (2003). link to paper\nGroup C. Theobald, C. M. & Talbot, M. The Bayesian choice of crop variety and fertilizer dose. Journal of the Royal Statistical Society: Series C (Applied Statistics) 51, 23–36 (2002). link to paper\nQuestions\n\nDescribe the decision problem! Who is the decision-maker? What are the decision alternatives? How are values/preferences defined and used? What qualifies as a good decision?\nDescribe the model to inform the decision problem. What is the quantify of interest? What type of data was used? How were priors specified?\nList sources of uncertainty for this assessment!\nDescribe strengths and weaknesses of the methods and principles underlying the paper as a method in research and as a method to produce scientific advice (decision-support).\n\n\n\nTheme 2: Uncertainty and subjective probability\nGroup A. Meder, B., Le Lec, F. & Osman, M. Decision making in uncertain times: what can cognitive and decision sciences say about or learn from economic crises? Trends in Cognitive Sciences 17, 257–260 (2013). link to paper\nGroup B. Paté-Cornell, E. On “Black Swans” and “Perfect Storms”: Risk Analysis and Management When Statistics Are Not Enough: On Black Swans and Perfect Storms. Risk Analysis 32, 1823–1833 (2012). link to paper\nGroup C. Parker, W. S. Whose probabilities? Predicting climate change with ensembles of models. Philosophy of Science 77, 985–997 (2010). link to paper\nQuestions\n\nWhat type of assessment or decision problem is used as context for the paper?\nHow is uncertainty presented or defined by the authors?\nWhat use of subjective probability is described and are there any requirements or justifications for this use?\nDo the authors suggest any limitations with subjective probability as a measure to quantify uncertainty in research and in processes that produce scientific advice? If so, which?\n\n\n\nTheme 3: Beyond the Bayesian paradigm\nGroup A. French, S. Axiomatizing the Bayesian Paradigm in Parallel Small Worlds. Operations Research (2020). link to paper\nGroup B. O’Hagan, A. & Oakley, J. E. Probability is perfect, but we can’t elicit it perfectly. Reliability Engineering & System Safety 85, 239–248 (2004). link to paper\nGroup C. Gärdenfors, Peter. & Sahlin, Nils. E. Unreliable probabilities, risk taking, and decision making. Synthese 53, 361–386 (1982). link to paper\nQuestions\n\nWhat challenges with the Bayesian paradigm are raised by the authors?\nWhat is their solution?\nDescribe strengths and weaknesses of the methods and principles proposed in the paper relevant and useful in research and in processes that produce scientific advice (decision-support)."
  },
  {
    "objectID": "pages/course_intro.html#individual-project",
    "href": "pages/course_intro.html#individual-project",
    "title": "Course introduction",
    "section": "Individual project",
    "text": "Individual project\nThe purpose of the individual project is to allow you to implement Bayesian analysis on a problem that you specify yourself. This can be something that is related to your research (but it doesn’t have to be). Select a problem making sure that the amount of work should not exceed more than a week.\nThe problem should be either a Bayesian analysis with an informed and justified prior or a Decision analysis supported by a Bayesian analysis\n\nShare your project idea\nGet early feedback from Ullrika/Zheng\nPerform the project\nProduce a minimal report (project description, what you did, result)\nGet feedback from Ullrika/Zheng\nThe project should preferably be finalised within a month after the last course day. Instructions to submit will follow\n\nIf you are new to Bayesian stuff - MAKE IT SIMPLE!\nIf you feel advanced - take the opportunity to try something new"
  },
  {
    "objectID": "pages/course_intro.html#practical-things",
    "href": "pages/course_intro.html#practical-things",
    "title": "Course introduction",
    "section": "Practical things",
    "text": "Practical things\nLADOK - contact your ladok-administrator with a request to be registered to the course with identity 6FNAM001.\nWe will issue certificates upon a completed course.\nPUB after the course today"
  },
  {
    "objectID": "pages/ex3_answers.html",
    "href": "pages/ex3_answers.html",
    "title": "Exercise 3 Answers",
    "section": "",
    "text": "# Metropolis Algorithm for Coin Flip Inference\n# 100 flips: 55 heads, 45 tails\n# Prior: Beta(1,1) which is uniform(0,1)\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Define observed data\nn_flips &lt;- 100      # Total number of coin flips\nn_heads &lt;- 55       # Observed number of heads\nn_tails &lt;- 45       # Observed number of tails (or n_flips - n_heads)\n\n# Define parameters for Metropolis algorithm\nn_iterations &lt;- 10000  # Number of MCMC iterations\nburn_in &lt;- 1000        # Number of initial iterations to discard\nproposal_sd &lt;- 0.1     # Standard deviation for proposal distribution\n\n# Initialize storage for samples\nsamples &lt;- numeric(n_iterations)  # Vector to store sampled theta values\ncurrent_theta &lt;- 0.5              # Starting value for theta (probability of heads)\n\n# Define the prior distribution (Beta distribution)\n# Beta(1,1) is uniform over [0,1], so density is 1 for all valid thetas\nprior_density &lt;- function(theta) {\n  if (theta &lt; 0 || theta &gt; 1) return(0)  # Prior is 0 outside [0,1]\n  dbeta(theta, 1, 1)  # Beta(1,1) density (always equals 1 for theta in [0,1])\n}\n\n# Define the likelihood function (binomial probability)\nlikelihood &lt;- function(theta) {\n  # Binomial likelihood: P(data|theta) = theta^{heads} * (1-theta)^{tails}\n  # Using dbinom for numerical stability\n  dbinom(n_heads, size = n_flips, prob = theta)\n}\n\n# Define the posterior density (up to proportionality constant)\nposterior_density &lt;- function(theta) {\n  prior_density(theta) * likelihood(theta)  # Prior * Likelihood\n}\n\n# Metropolis algorithm main loop\nfor (i in 1:n_iterations) {\n  \n  # 1. Propose a new candidate value\n  # Use normal distribution centered at current theta\n  # Note: This can propose values outside [0,1]\n  proposed_theta &lt;- rnorm(1, mean = current_theta, sd = proposal_sd)\n  \n  # 2. Calculate acceptance ratio\n  # Ratio of posterior densities: P(proposed)/P(current)\n  # If proposed theta is invalid (outside [0,1]), posterior is 0\n  if (proposed_theta &lt; 0 || proposed_theta &gt; 1) {\n    acceptance_ratio &lt;- 0  # Reject proposals outside valid range\n  } else {\n    acceptance_ratio &lt;- posterior_density(proposed_theta) / \n                       posterior_density(current_theta)\n  }\n  \n  # 3. Accept or reject the proposal\n  # Generate uniform random number for acceptance decision\n  u &lt;- runif(1)\n  if (u &lt; acceptance_ratio) {\n    current_theta &lt;- proposed_theta  # Accept proposal\n  }\n  # If u &gt;= acceptance_ratio, keep current_theta (implicitly)\n  \n  # 4. Store the current theta value\n  samples[i] &lt;- current_theta\n}\n\n# Discard burn-in samples\npost_burn_samples &lt;- samples[(burn_in + 1):n_iterations]\n\n# Calculate posterior summary statistics\nposterior_mean &lt;- mean(post_burn_samples)\nposterior_median &lt;- median(post_burn_samples)\nposterior_sd &lt;- sd(post_burn_samples)\n\n# Calculate 95% credible interval\ncredible_interval &lt;- quantile(post_burn_samples, c(0.025, 0.975))\n\n# Display results\ncat(\"=== Metropolis Algorithm Results ===\\n\")\n\n=== Metropolis Algorithm Results ===\n\ncat(\"Observed data: \", n_heads, \"heads out of\", n_flips, \"flips\\n\")\n\nObserved data:  55 heads out of 100 flips\n\ncat(\"Posterior mean (probability of heads):\", round(posterior_mean, 4), \"\\n\")\n\nPosterior mean (probability of heads): 0.5492 \n\ncat(\"Posterior median:\", round(posterior_median, 4), \"\\n\")\n\nPosterior median: 0.5496 \n\ncat(\"Posterior standard deviation:\", round(posterior_sd, 4), \"\\n\")\n\nPosterior standard deviation: 0.0495 \n\ncat(\"95% Credible Interval: [\", \n    round(credible_interval[1], 4), \", \", \n    round(credible_interval[2], 4), \"]\\n\", sep = \"\")\n\n95% Credible Interval: [0.4511, 0.6446]\n\n# For comparison: Analytical solution with Beta-Binomial conjugacy\n# Prior: Beta(1,1), Likelihood: Binomial(100, theta)\n# Posterior: Beta(1 + 55, 1 + 45) = Beta(56, 46)\nanalytical_mean &lt;- 56 / (56 + 46)\nanalytical_sd &lt;- sqrt((56 * 46) / ((56 + 46)^2 * (56 + 46 + 1)))\ncat(\"\\n=== Analytical Solution (for comparison) ===\\n\")\n\n\n=== Analytical Solution (for comparison) ===\n\ncat(\"Beta(56, 46) posterior\\n\")\n\nBeta(56, 46) posterior\n\ncat(\"Analytical mean:\", round(analytical_mean, 4), \"\\n\")\n\nAnalytical mean: 0.549 \n\ncat(\"Analytical SD:\", round(analytical_sd, 4), \"\\n\")\n\nAnalytical SD: 0.049 \n\n# Plotting the results\npar(mfrow = c(2, 2))  # Create 2x2 grid of plots\n\n# 1. Trace plot (shows MCMC sampling path)\nplot(1:length(post_burn_samples), post_burn_samples, type = \"l\",\n     xlab = \"Iteration (after burn-in)\", ylab = \"Theta\",\n     main = \"Trace Plot\", col = \"blue\", lwd = 0.5)\n\n# 2. Histogram of posterior samples\nhist(post_burn_samples, breaks = 30, probability = TRUE,\n     xlab = \"Theta (probability of heads)\", \n     main = \"Posterior Distribution\",\n     col = \"lightblue\", border = \"white\")\n# Add analytical posterior density curve\ncurve(dbeta(x, 56, 46), add = TRUE, col = \"red\", lwd = 2)\nlegend(\"topright\", legend = c(\"MCMC\", \"Analytical\"), \n       col = c(\"lightblue\", \"red\"), lwd = c(5, 2), bty = \"n\")\n\n# 3. Running mean (shows convergence)\nrunning_mean &lt;- cumsum(post_burn_samples) / (1:length(post_burn_samples))\nplot(1:length(post_burn_samples), running_mean, type = \"l\",\n     xlab = \"Iteration\", ylab = \"Running Mean\",\n     main = \"Running Mean of Theta\",\n     col = \"darkgreen\", lwd = 1)\nabline(h = analytical_mean, col = \"red\", lty = 2, lwd = 2)\n\n# 4. Autocorrelation plot\nacf(post_burn_samples, main = \"Autocorrelation\", \n    xlab = \"Lag\", ylab = \"ACF\", col = \"purple\")\n\n\n\n\n\n\n\n# Reset plot layout\npar(mfrow = c(1, 1))\n\n# Calculate effective sample size (ESS)\n# ESS = n / (1 + 2*sum(autocorrelations))\n# Rough estimate for demonstration\nacf_vals &lt;- acf(post_burn_samples, plot = FALSE)$acf\ness &lt;- length(post_burn_samples) / (1 + 2 * sum(acf_vals[-1]))\ncat(\"\\nEffective Sample Size (approximate):\", round(ess, 0), \"\\n\")\n\n\nEffective Sample Size (approximate): 1790"
  },
  {
    "objectID": "pages/exercise_2.html",
    "href": "pages/exercise_2.html",
    "title": "Conjugate models",
    "section": "",
    "text": "Background\nConjugate models are very useful even today, but for relatively simple problems.\n\n\nTask 1\nTest an hypothesis using conjugate model. How sensitive is the conclusion from the choice of prior?\nLet \\(\\lambda\\) be the average number of goals scored in a Women’s World Cup game. We’ll analyse \\(\\lambda\\) by a Gamma-Poisson model where data \\(Y_i\\) is the observed number of goals scored in a sample of World Cup games\n\nSpecify the model\nPlot and summarize our prior understanding of \\(\\lambda\\).\nWhy is the Poisson model a reasonable choice for our data\n\\(Y_i\\)?\n\nUse the wwc_2019_matches data from fivethirtyeight\nThe wwc_2019_matches data includes the number of goals scored by the two teams in each 2019 Women’s World Cup match. We summed the scores by the two teams per game, made a histogram and calculated some summary statistics:\n\n\nSome larger datasets need to be installed separately, like senators and\nhouse_district_forecast. To install these, we recommend you install the\nfivethirtyeightdata package by running:\ninstall.packages('fivethirtyeightdata', repos =\n'https://fivethirtyeightdata.github.io/drat/', type = 'source')\n\n\n\n\n\n\n\n\n\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   2.000   3.000   2.808   3.000  13.000 \n\n\n\nMake a test if the average number of goals scored in a Women’s World Cup game is less than 1.8.\n\n\n\nTask 2\nUse conjugate models to construct probability intervals for the results from a clinical trial and compare to a published meta-analysis.\nLancet paper\n\nA relative risk (RR) is a ratio of the probability of an event occurring in the exposed group versus the probability of the event occurring in the non-exposed group.\n\nReproduce the probability interval for a RR from the forest plots tables e.g. Scales et al 2003\nCalculate a probability interval for one of the studies for which the RR is not calculable, e.g. Hall et al 2014"
  },
  {
    "objectID": "pages/MCMC.html",
    "href": "pages/MCMC.html",
    "title": "MCMC-sampling",
    "section": "",
    "text": "describe what is a Markov chain monte carlo (MCMC)\ndescribe the purpose and applicability range of MCMC\ncompare the strength and weakness of MCMC with other posterior estimation methods\ndevelop a simple MCMC (complete exercise 3)\ndescribe MCMC diagnostics"
  },
  {
    "objectID": "pages/MCMC.html#learning-goals",
    "href": "pages/MCMC.html#learning-goals",
    "title": "MCMC-sampling",
    "section": "",
    "text": "describe what is a Markov chain monte carlo (MCMC)\ndescribe the purpose and applicability range of MCMC\ncompare the strength and weakness of MCMC with other posterior estimation methods\ndevelop a simple MCMC (complete exercise 3)\ndescribe MCMC diagnostics"
  },
  {
    "objectID": "pages/MCMC.html#beta-binomial-conjugation",
    "href": "pages/MCMC.html#beta-binomial-conjugation",
    "title": "MCMC-sampling",
    "section": "Beta-binomial conjugation",
    "text": "Beta-binomial conjugation\nBinomial likelihood:\nn Bernoulli trials with y successes and unknown probability of success \\(\\theta\\).\n\\[\n\\text{Binomial}(n, y,\\theta)\n\\]\nThe prior is a beta distribution:\n\\[\nBeta(\\alpha, \\beta)\n\\]\nConjugation: the posterior distribution is also a beta distribution:\n\\[\n  Beta(\\alpha + y, \\beta + n - y)\n\\]"
  },
  {
    "objectID": "pages/MCMC.html#posterior-computation",
    "href": "pages/MCMC.html#posterior-computation",
    "title": "MCMC-sampling",
    "section": "Posterior computation",
    "text": "Posterior computation\n\nAnalytical solution: conjugation often impossible\nGrid approximation: possible but efficiency drops exponentialy with dimension\nLaPlace approximation: assumption of multivariate normality often not applicable\nMarkov Chain Monte Carlo (MCMC): flexible, efficient"
  },
  {
    "objectID": "pages/MCMC.html#what-is-mcmc",
    "href": "pages/MCMC.html#what-is-mcmc",
    "title": "MCMC-sampling",
    "section": "What is MCMC",
    "text": "What is MCMC\n\nMarkov chain\n\nMarkov process: \\(f(t+1)=g(f(t),noise)\\)\nChain\n\nMonte Carlo: a large number of samples can approximate the distribution\n\nMCMC transforms the question:\nFROM:\nGetting the posterior distribution\nTO\nGetting enough representative samples from the posterior distribution"
  },
  {
    "objectID": "pages/MCMC.html#example-island-hopping",
    "href": "pages/MCMC.html#example-island-hopping",
    "title": "MCMC-sampling",
    "section": "Example: Island hopping",
    "text": "Example: Island hopping\n\nMake a proposal.\nAcceptance ratio \\(p_{prop}=\\frac{poposal}{current}\\).\nIf \\(p_{prop}\\) &gt; 1, move; if \\(p_{prop}\\)=1, stay.\nIf \\(p_{prop}\\) &lt; 1, generate a random value k between (0,1). If \\(k&lt;p_{prop}\\), then move.\nrepeat 1-4.\n\n\nSimulate the hopping process\nNumber of islands (parameter values) unknown in reality.\n\n\n\n\n\n\n\n\n\n\n\n# Function to implement the Metropolis algorithm\ntarget_distribution &lt;- sapply(1:num_island,function(x){\n    prob = x/sum(1:num_island)\n  })\n\nmetropolis_island_hopping &lt;- function(num_iterations, starting_island = round(num_island/2,0),true_prob = target_distribution) {\n  # Number of islands\n  num_islands &lt;- num_island\n  \n  # Define transition probabilities (in this case, uniform)\n  # This means proposals are equally likely to jump to adjacent islands\n  \n  # Initialize chain\n  chain &lt;- numeric(num_iterations)\n  chain[1] &lt;- starting_island\n  \n  # Define stationary distribution (target)\n  # In this example, we'll use a uniform distribution\n  target_distribution &lt;- true_prob\n  \n  # Run Metropolis algorithm\n  for (i in 2:num_iterations) {\n    current &lt;- chain[i-1]\n    \n    # Propose a move: randomly jump to an adjacent island or stay\n    # For simplicity, adjacency is defined as +/- 1 \n    jump &lt;- sample(c(-1, 0, 1), 1)\n    proposed &lt;- current + jump\n    \n    # Check boundaries and wrap around (circular islands)\n    if (proposed &lt; 1) {\n      proposed &lt;- num_islands + proposed\n    } else if (proposed &gt; num_islands) {\n      proposed &lt;- proposed - num_islands\n    }\n    \n    # Calculate acceptance probability\n    acceptance_ratio &lt;- target_distribution[proposed] / target_distribution[current]\n    acceptance_prob &lt;- min(1, acceptance_ratio)\n    \n    # Accept or reject the proposal\n    if (runif(1) &lt; acceptance_prob) {\n      chain[i] &lt;- proposed  # Accept move\n    } else {\n      chain[i] &lt;- current   # Reject move, stay at current island\n    }\n  }\n  \n  return(chain)\n}\n\n\n\nn_iter = 1000\nchain = metropolis_island_hopping(num_iterations = n_iter)\n\nhopping_freq = table(chain) / n_iter\nhopping_prob = numeric(num_island)\nfor (i in 1:num_island) {\n  hopping_prob[i] &lt;- sum(chain == i) / n_iter\n}\nhopping_results = tibble(\n  islands = 1:num_island,\n  freq = hopping_prob\n)\nhopping_results\n\n# A tibble: 5 × 2\n  islands  freq\n    &lt;int&gt; &lt;dbl&gt;\n1       1 0.069\n2       2 0.131\n3       3 0.203\n4       4 0.255\n5       5 0.342\n\n\n\n\ntrace_data &lt;- data.frame(\n  Iteration = 1:n_iter,\n  Island = chain[1:n_iter]\n)\np2 &lt;- ggplot(trace_data, aes(x = Iteration, y = Island)) +\n  geom_line() +\n  geom_point(size = 1) +\n  labs(title = \"Trace Plot\",\n       x = \"Iteration\",\n       y = \"Island Number\") +\n  scale_y_continuous(breaks = 1:num_island) +\n  theme_minimal()\np2\n\n\n\n\n\n\n\n\n\n\nSummary of hopping\nWhen repeated enough times, frequency on any island matches the relative population of the island.\nThree critical things:\n\nknown your position and adjacent options\nmaking a proposal and knowing the population of the proposal\nknowing the population of the current, to calculate the acceptance ratio \\(p_{prop}=\\frac{proposal}{current}\\)."
  },
  {
    "objectID": "pages/MCMC.html#metropolis-algorithm",
    "href": "pages/MCMC.html#metropolis-algorithm",
    "title": "MCMC-sampling",
    "section": "Metropolis algorithm",
    "text": "Metropolis algorithm\n\nIsland hopping is a special case, Metropolis algorithm could handle:\n\ncontinuous positions\nmore than one dimension\ncomplex proposals\n\n\\[\ny=\\beta_0 + \\beta_1 x + \\epsilon\n\\]\nModel:\n\\[\n\\begin{equation}\n\\begin{split}\n\\eta \\sim N(0,\\sigma^2) \\\\\ny \\sim N(\\beta_0 + \\beta_1 x, \\epsilon)\n\\end{split}\n\\end{equation}\n\\]\n\\(\\beta_0, \\beta_1\\) are continuous parameters\nLikelihood:\n\\[\np(Y|\\beta_0,\\beta_1,\\epsilon,x)=\\prod_i^{n} \\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp(-\\frac{(y-(\\beta_0+\\beta_1 x))^2}{2\\sigma^2})\n\\]\nPriors:\n\\(\\beta_0 \\sim N(0,5)\\).\nHow does the island hopping analogy work here?"
  },
  {
    "objectID": "pages/MCMC.html#exercise-3",
    "href": "pages/MCMC.html#exercise-3",
    "title": "MCMC-sampling",
    "section": "Exercise 3",
    "text": "Exercise 3\nComplete Ex 3: today and beginning of tomorrow’s session."
  },
  {
    "objectID": "pages/MCMC.html#mcmc-diagnostics",
    "href": "pages/MCMC.html#mcmc-diagnostics",
    "title": "MCMC-sampling",
    "section": "MCMC diagnostics",
    "text": "MCMC diagnostics\nBefore accepting MCMC results, how good they are?\n\nTrace plot: displays chain stability in random sampling,\nRhat/ Gelman-Rubins statistics: convergence of multiple chains\nEffective sample size: measures chain accuracy- how many independent sampling steps for the chain to approximate the posterior\nAutocorrelation: also shows chain accuracy- strong correlation between steps that are one or two steps apart is bad.\n\nRead the Bayes rule book chapter 6.3 and DBDA chapter 7.5 for technical details and examples."
  }
]