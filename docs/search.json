[
  {
    "objectID": "pages/solution_mcmc_coin.html",
    "href": "pages/solution_mcmc_coin.html",
    "title": "Solution to Exercise Coin flip in R",
    "section": "",
    "text": "For comparison: Analytical solution with Beta-Binomial conjugation\n\n# Prior: Beta(1,1), Likelihood: Binomial(100, theta)\n# Posterior: Beta(1 + 55, 1 + 45) = Beta(56, 46)\nanalytical_mean &lt;- 56 / (56 + 46)\nanalytical_sd &lt;- sqrt((56 * 46) / ((56 + 46)^2 * (56 + 46 + 1)))\n\nUsing MCMC\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Metropolis Algorithm for Coin Flip\n# 100 flips: 55 heads, 45 tails\n# Prior: Beta(1,1)\n\n# Define observed data\nn_flips &lt;- 100      # Total number of coin flips\nn_heads &lt;- 55       # Observed number of heads\nn_tails &lt;- 45       # Observed number of tails (or n_flips - n_heads)\n\n# Define parameters for Metropolis algorithm\nn_iterations &lt;- 1000  # Number of MCMC iterations\nstarting_theta &lt;- 0.5\nproposal_sd &lt;- 0.1\n\n# Define the prior distribution (Beta distribution)\n# Beta(1,1) is uniform over [0,1], so density is 1 for all valid thetas\nprior_density &lt;- function(theta) {\n  if (theta &lt; 0 || theta &gt; 1) return(0)  # Prior is 0 outside [0,1]\n  dbeta(theta, 1, 1)  # Beta(1,1) \n}\n\n# Define the likelihood function (binomial probability)\nlikelihood_density &lt;- function(theta) {\n  # Binomial likelihood: P(data|theta) = theta^{heads} * (1-theta)^{tails}\n  dbinom(n_heads, size = n_flips, prob = theta)\n}\n\n# Define the posterior density (up to proportionality constant)\nposterior_density &lt;- function(theta) {\n  prior_density(theta) * likelihood(theta)  # Prior * Likelihood\n}\n\n\n# store the positions\nchain_theta &lt;- numeric(n_iterations)\nprior_values &lt;- numeric(n_iterations)\nlikelihood_values &lt;- numeric(n_iterations)\nposterior_values &lt;- numeric(n_iterations)\nacceptance_ratios &lt;- numeric(n_iterations - 1)\n\n# Calculate values for initial position\nchain_theta[1] &lt;- starting_theta\nprior_values[1] &lt;- prior_density(chain_theta[1])\nlikelihood_values[1] &lt;- likelihood_density(chain_theta[1])\nposterior_values[1] &lt;- prior_values[1] * likelihood_values[1]  # Unnormalized posterior\n\n\n# Metropolis algorithm main loop\nfor (i in 2:n_iterations) {\n  current_theta &lt;- chain_theta[i-1]\n  \n  # 1. Propose a new candidate value\n  # random walk\n  proposed_theta &lt;- rnorm(1, mean = current_theta, sd = proposal_sd)\n  if (proposed_theta &lt; 0) {proposed_theta &lt;- 1/(-proposed_theta)}\n  if (proposed_theta &gt; 1) {proposed_theta &lt;- 1/proposed_theta}\n  proposed_theta &lt;- max(0.001, min(0.999, proposed_theta))\n\n  # 2. Calculate acceptance ratio\n  # Ratio of posterior densities: P(proposed)/P(current)\n  # Calculate posterior for CURRENT state\n  prior_current &lt;- prior_density(current_theta)\n  likelihood_current &lt;- likelihood_density(current_theta)\n  posterior_current &lt;- prior_current * likelihood_current  # Unnormalized\n    \n  # Calculate posterior for PROPOSED state\n  prior_proposed &lt;- prior_density(proposed_theta)\n  likelihood_proposed &lt;- likelihood_density(proposed_theta)\n  posterior_proposed &lt;- prior_proposed * likelihood_proposed  # Unnormalized\n  \n  acceptance_ratio &lt;- posterior_proposed / posterior_current\n  acceptance_prob &lt;- min(1, acceptance_ratio)\n  \n  # Store the computed values\n  prior_values[i-1] &lt;- prior_current\n  likelihood_values[i-1] &lt;- likelihood_current\n  posterior_values[i-1] &lt;- posterior_current\n  acceptance_ratios[i-1] &lt;- acceptance_prob\n\n  # 3. Accept or reject the proposal\n  if (runif(1) &lt; acceptance_ratio) {\n    chain_theta[i] &lt;- proposed_theta\n    current_theta &lt;- proposed_theta  # Accept proposal\n  } else {\n    chain_theta[i] &lt;- current_theta\n  }\n}\n\n\n# summarize \nprior_values[n_iterations] &lt;- prior_density(chain_theta[n_iterations])\nlikelihood_values[n_iterations] &lt;- likelihood_density(chain_theta[n_iterations])\nposterior_values[n_iterations] &lt;- prior_values[n_iterations] * likelihood_values[n_iterations]\n\nsummary(posterior_values)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0003065 0.0403837 0.0638151 0.0564847 0.0745909 0.0799855 \n\ntrace_df &lt;- data.frame(\n  iteration = 1:n_iterations,\n  theta = chain_theta\n)\n\np_trace &lt;- ggplot(trace_df, aes(x = iteration, y = theta)) +\n  geom_line(alpha = 0.5, color = \"gray\") +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_hline(yintercept = n_heads/n_flips, color = \"red\", linetype = \"dashed\", size = 1) +\n  # scale_color_manual(values = c(\"FALSE\" = \"red\", \"TRUE\" = \"green\"), \n  #                    na.value = \"black\", name = \"Accepted\") +\n  theme_classic() +\n  labs(title = \"Trace Plot of theta (Probability of Heads)\",\n       # subtitle = paste(\"Red dashed line: Observed proportion =\", round(n_heads/n_flips, 3)),\n       x = \"Iteration\",\n       y = \"theta\") +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +\n  theme(legend.position = \"bottom\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\np_trace"
  },
  {
    "objectID": "pages/PP.html",
    "href": "pages/PP.html",
    "title": "Predictive Performance",
    "section": "",
    "text": "Describe how prior and data influence posterior distributions\n\n\nApply this understanding to interpret posterior predictions across different scenarios with varying priors (flat, informed) and data (sparse, abundant)\nReflect on the ethical and practical implication of prior choices in modeling\n\n\nDescribe the purpose of evaluating predictive performance\n\n\nDescribe why evaluation of predictive performance is necessary for model validation, generalization and avoiding overfitting\nDescribe the difference between in-sample and out-of-sample evaluation of predictive performance\nReflect on the limitations of relying solely on predictive performance for decision making\n\n\nDescribe categories of predictive performance metrics\n\n\nDescribe the key difference between the categories\nDescribe Bayesian predictive measures"
  },
  {
    "objectID": "pages/PP.html#learning-goals",
    "href": "pages/PP.html#learning-goals",
    "title": "Predictive Performance",
    "section": "",
    "text": "Describe how prior and data influence posterior distributions\n\n\nApply this understanding to interpret posterior predictions across different scenarios with varying priors (flat, informed) and data (sparse, abundant)\nReflect on the ethical and practical implication of prior choices in modeling\n\n\nDescribe the purpose of evaluating predictive performance\n\n\nDescribe why evaluation of predictive performance is necessary for model validation, generalization and avoiding overfitting\nDescribe the difference between in-sample and out-of-sample evaluation of predictive performance\nReflect on the limitations of relying solely on predictive performance for decision making\n\n\nDescribe categories of predictive performance metrics\n\n\nDescribe the key difference between the categories\nDescribe Bayesian predictive measures"
  },
  {
    "objectID": "pages/PP.html#the-rationale-for-model-evaluation-and-comparison",
    "href": "pages/PP.html#the-rationale-for-model-evaluation-and-comparison",
    "title": "Predictive Performance",
    "section": "The rationale for model evaluation and comparison",
    "text": "The rationale for model evaluation and comparison\nModel evaluation: how good is this model?\n\nGoodness-of-fit: Is the model good enough (for the data)?\nPredictive performance: Can the model make good predictions for new data?\n\nModel comparison: Is the model better than other models?\nTwo critical issues:\n\nLack of fit\nOverfitting\nGeneralization with context"
  },
  {
    "objectID": "pages/PP.html#overfitting",
    "href": "pages/PP.html#overfitting",
    "title": "Predictive Performance",
    "section": "Overfitting",
    "text": "Overfitting\n\n\n\nBest example of overfitting\n\n\nIn MCMC, overfitting, i.e., having more parameters than needed may cause three things:\n\nThe predictions are too good to be true\nDivergence statistics are bad\nPosteriors for individual parameters have huge dispersion\n\nIdentifiability issue: MCMC can’t tell influence on the likelihood come from which parameter"
  },
  {
    "objectID": "pages/PP.html#predictive-performance-metrics-for-bayesian-models",
    "href": "pages/PP.html#predictive-performance-metrics-for-bayesian-models",
    "title": "Predictive Performance",
    "section": "Predictive performance metrics for Bayesian models",
    "text": "Predictive performance metrics for Bayesian models\nBayesian models have a full posterior distribution already!\nWith sufficient computing power, no reason not to use full predictive distribution.\nExpected log predictive density (elpd)\n\\[\nelpd(y,\\tilde{y}_i) = \\sum^n_{i=1}{\\int{p_t (\\tilde{y}_i)\\log \\ p(\\tilde{y}_i |y)\\ d \\tilde{y}_i}}\n\\]\nelpd can be used for computing Widely-applicable information criterion or leave-one-out cross validation.\nExpansion reads:\nVehtari, A.; Gelman, A.; Gabry, J. Practical Bayesian model evaluation using leave-one-out516 cross-validation and WAIC. Statistics and Computing 2017, 27, 1413–1432"
  },
  {
    "objectID": "pages/PP.html#generalization-with-practical-context",
    "href": "pages/PP.html#generalization-with-practical-context",
    "title": "Predictive Performance",
    "section": "Generalization with practical context",
    "text": "Generalization with practical context\nScope of evaluation: in-sample vs out-of-sample\nA model to predict ice cream consumption based on swimming activity.\nIf the model is trained on survey data by people in Lund in summer, will the predictions apply to people in Malmö winter?\nWill the predictions apply to people in Qatar (in desert) in summer?"
  },
  {
    "objectID": "pages/PP.html#out-of-sample-evaluation",
    "href": "pages/PP.html#out-of-sample-evaluation",
    "title": "Predictive Performance",
    "section": "Out-of-sample evaluation",
    "text": "Out-of-sample evaluation\nCross-validation\n\n\n\nK-fold cross validation\n\n\nTrue remedy to out-of-sample prediction problem is to improve the representativeness of sampling protocol. - Not necessarily related to sample size - Be aware of bias in sampling protocol and reduce the bias"
  },
  {
    "objectID": "pages/PP.html#category-of-predictive-performance-metrics",
    "href": "pages/PP.html#category-of-predictive-performance-metrics",
    "title": "Predictive Performance",
    "section": "Category of predictive performance metrics",
    "text": "Category of predictive performance metrics\n\n\n\n\n\n\n\n\nCategory\nDescription\nExample\n\n\n\n\nCentral tendency\nConsiders ONLY the mean distance between observed and predictive values\nMean Rooted Squared Errors\n\n\nIncomplete uncertainty\nIn addition to central tendency, also considers uncertainty from the spread (variance)\nRanked Probability Score\n\n\nComplete uncertainty\nFull predictive density distribution\nExpected Log Predictive Density"
  },
  {
    "objectID": "pages/exercise_4.html",
    "href": "pages/exercise_4.html",
    "title": "MCMC sampling software",
    "section": "",
    "text": "Gibbs sampling and BUGS\n\n\nStrength: Simple coding and similar to basic Metropolis algorithm\nWeakness: Really random walks, poor at dealing with complex problems\n\n\nHamilton MC and stan\n\n\nStrength: Uses gradient information to explore high-dimensional, correlated parameter space more efficiently\nWeakness: Requires more coding efforts"
  },
  {
    "objectID": "pages/exercise_4.html#mcmc-sampling-software",
    "href": "pages/exercise_4.html#mcmc-sampling-software",
    "title": "MCMC sampling software",
    "section": "",
    "text": "Gibbs sampling and BUGS\n\n\nStrength: Simple coding and similar to basic Metropolis algorithm\nWeakness: Really random walks, poor at dealing with complex problems\n\n\nHamilton MC and stan\n\n\nStrength: Uses gradient information to explore high-dimensional, correlated parameter space more efficiently\nWeakness: Requires more coding efforts"
  },
  {
    "objectID": "pages/exercise_4.html#stan-ecosystem",
    "href": "pages/exercise_4.html#stan-ecosystem",
    "title": "MCMC sampling software",
    "section": "Stan ecosystem",
    "text": "Stan ecosystem\n\nsampler: rstan, cmdstanr, CmdStanPy, PyMC\nhigh-level utility package: rstanarm, brms, PyStan, bambi and more"
  },
  {
    "objectID": "pages/exercise_4.html#getting-start-with-stan",
    "href": "pages/exercise_4.html#getting-start-with-stan",
    "title": "MCMC sampling software",
    "section": "Getting start with Stan",
    "text": "Getting start with Stan\n\nInstallation\n\nIf you Use R: install cmdstanr\nIf you Use python: install cmdstanPy\n\ninstall appropriate C++ toolchain based on your IDE: for R and for python\ninstall compiler for your IDE\ninstall utility package if desire\n\n\nOnce done, run an example model to check the compiler\n\nThe beta-binomial example in stan\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.9.0\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: C:/Users/ekol-usa/.cmdstan/cmdstan-2.36.0\n\n\n- CmdStan version: 2.36.0\n\n\n\nA newer version of CmdStan is available. See ?install_cmdstan() to install it.\nTo disable this check set option or environment variable cmdstanr_no_ver_check=TRUE.\n\nfile &lt;- file.path(cmdstan_path(), \"examples\", \"bernoulli\", \"bernoulli.stan\")\nmod &lt;- cmdstan_model(file)\n# names correspond to the data block in the Stan program\ndata_list &lt;- list(N = 10, y = c(0,1,0,0,0,0,0,0,0,1))\n\n# call out the stan script\nmod$print()\n\ndata {\n  int&lt;lower=0&gt; N;\n  array[N] int&lt;lower=0, upper=1&gt; y;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(1, 1); // uniform prior on interval 0,1\n  y ~ bernoulli(theta);\n}\n\n\nSampling\n\nfit &lt;- mod$sample(\n  data = data_list,\n  seed = 123,\n  chains = 4\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 1.0 seconds.\n\n\n\nExtract model diagnostics\n\n\n# install.package(c(\"bayesplot\",\"tidyverse\"))\nlibrary(bayesplot)\n\nThis is bayesplot version 1.15.0\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCheck rhat and effecti sample size:\n\n# all parameters\nfit$summary()\n\n# A tibble: 2 × 10\n  variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__     -7.27  -6.99  0.750 0.323 -8.74   -6.75   1.00    1924.    2287.\n2 theta     0.252  0.239 0.120 0.122  0.0806  0.477  1.00    1368.    1664.\n\n\nRhat should be as close to 1 as possible\nESS: ideally number of sampling steps from all chains\nTraceplot:\n\n# all parameters\nmcmc_trace(fit$draws())\n\n\n\n\n\n\n\n# specific parameter\nmcmc_trace(fit$draws(\"theta\"))\n\n\n\n\n\n\n\n\nAutocorrelation:\n\n# all parameters\nmcmc_acf(fit$draws())\n\n\n\n\n\n\n\n\nWhen something goes wrong, check this"
  },
  {
    "objectID": "pages/exercise_2.html",
    "href": "pages/exercise_2.html",
    "title": "Conjugate models",
    "section": "",
    "text": "Background\nConjugate models are very useful even today, but for relatively simple problems.\n\n\nTask 1\nTest an hypothesis using conjugate model. How sensitive is the conclusion from the choice of prior?\nLet \\(\\lambda\\) be the average number of goals scored in a Women’s World Cup game. We’ll analyse \\(\\lambda\\) by a Gamma-Poisson model where data \\(Y_i\\) is the observed number of goals scored in a sample of World Cup games\n\nSpecify the model\nPlot and summarize our prior understanding of \\(\\lambda\\).\nWhy is the Poisson model a reasonable choice for our data\n\\(Y_i\\)?\n\nUse the wwc_2019_matches data from fivethirtyeight\nThe wwc_2019_matches data includes the number of goals scored by the two teams in each 2019 Women’s World Cup match. We summed the scores by the two teams per game, made a histogram and calculated some summary statistics:\n\n\nSome larger datasets need to be installed separately, like senators and\nhouse_district_forecast. To install these, we recommend you install the\nfivethirtyeightdata package by running:\ninstall.packages('fivethirtyeightdata', repos =\n'https://fivethirtyeightdata.github.io/drat/', type = 'source')\n\n\n\n\n\n\n\n\n\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   2.000   3.000   2.808   3.000  13.000 \n\n\n[1] 52\n\n\n\nMake a test if the average number of goals scored in a Women’s World Cup game is less than 1.8.\n\n\n\nTask 2\nUse conjugate models to construct probability intervals for the results from a clinical trial and compare to a published meta-analysis.\nLancet paper\n\nA relative risk (RR) is a ratio of the probability of an event occurring in the exposed group versus the probability of the event occurring in the non-exposed group.\n\nReproduce the probability interval for a RR from the forest plots tables e.g. Scales et al 2003\nCalculate a probability interval for one of the studies for which the RR is not calculable, e.g. Hall et al 2014"
  },
  {
    "objectID": "pages/decision_theory.html",
    "href": "pages/decision_theory.html",
    "title": "Decision theory",
    "section": "",
    "text": "Agents\nDecision alternatives\nPreferences over outcomes\nImpact on outcomes for each decision alternative\nAn idea of what is a good decision\n\nDecision rules:\nBayesian Decision Theory: Maximise expected utility\nThere are other decision rules!"
  },
  {
    "objectID": "pages/decision_theory.html#generic-setup-for-decison-making",
    "href": "pages/decision_theory.html#generic-setup-for-decison-making",
    "title": "Decision theory",
    "section": "",
    "text": "Agents\nDecision alternatives\nPreferences over outcomes\nImpact on outcomes for each decision alternative\nAn idea of what is a good decision\n\nDecision rules:\nBayesian Decision Theory: Maximise expected utility\nThere are other decision rules!"
  },
  {
    "objectID": "pages/decision_theory.html#dt",
    "href": "pages/decision_theory.html#dt",
    "title": "Decision theory",
    "section": "DT",
    "text": "DT\n\nDescriptive: What people actually do, or have done\nPrescriptive: What people shoudl and can do\nNormative: What people should do (in theory, e.g. if rational)\n\nMedium read on Decision theory at Stanford Encyclopedia of Philosophy Archive"
  },
  {
    "objectID": "pages/decision_theory.html#preferences",
    "href": "pages/decision_theory.html#preferences",
    "title": "Decision theory",
    "section": "Preferences",
    "text": "Preferences\nAn agent prefers option \\(A\\) over \\(B\\) means that the agents takes \\(A\\) to be more desirable or choice-worthy than \\(B\\)\nIndifference \\(\\sim\\)\nWeak preference \\(\\preccurlyeq\\)\nStrong preference \\(\\prec\\)\nRational preferences of options can be seen to be given by:\n\nCompleteness\n\nFor any \\(A, B\\in S:\\text{ either }A \\preccurlyeq B\\text{ or } B \\preccurlyeq A\\)\n\nTransitivity\n\nFor any \\(A, B, C \\in S: \\text{ if }A\\preccurlyeq B\\text{ and } B\\preccurlyeq C \\text{ then } A \\preccurlyeq C\\)"
  },
  {
    "objectID": "pages/decision_theory.html#utilities",
    "href": "pages/decision_theory.html#utilities",
    "title": "Decision theory",
    "section": "Utilities",
    "text": "Utilities\nUtility as a way to measure preferences\n\\[\\text{For any }A,B \\in S: u(A)\\leq u(B) \\Longleftrightarrow A \\preccurlyeq B\\]"
  },
  {
    "objectID": "pages/decision_theory.html#maximise-expected-utility",
    "href": "pages/decision_theory.html#maximise-expected-utility",
    "title": "Decision theory",
    "section": "Maximise Expected Utility",
    "text": "Maximise Expected Utility\nLet \\(p_{ik}\\) be the the probability for outcome \\(O_{ik}\\) in lottery \\(L_i\\)\nvon Newmann Morgenstern representation theorem of the expected utility of lottery \\(L_i\\)\n\\[EU(L_i)=\\sum_ku(O_{ik})\\cdot p_{ik}\\]"
  },
  {
    "objectID": "pages/decision_theory.html#subjective-expected-utility-seu",
    "href": "pages/decision_theory.html#subjective-expected-utility-seu",
    "title": "Decision theory",
    "section": "Subjective Expected Utility (SEU)",
    "text": "Subjective Expected Utility (SEU)\nSavage\nSet of outcomes \\(\\mathbf{O}\\) - target of desire\nSet of states of the world \\(\\mathbf{S}\\) - target of belief\nAn act can be seen as a function from the states to outcomes. We have at least to acts \\(f\\) and \\(g\\)\n\\(f(s_i)\\) denotes the outcome of act \\(f\\) when event \\(s_i \\in \\mathbf{S}\\) is actually happening\nThe expected utility of act \\(f\\) is given by Savage’s equation\n\\[U(f)=\\sum_i u(f(s_i))\\cdot p(s_i)\\]\nSavage defined six axioms, which when satisfied, generates that a persons belief can be represented by a unique probability function which relates the theory to the theory to maximise expected utility (von Newmann Morgenstern representation theorem)\n\nTo maximise expected utility can be seen as a decision rule for decision problems where the probability of different outcomes are known or when the probability for different outcomes represents a persons belief about that outcome.\n\n\nIt is possible to derive a persons belief by asking here to choose between options. This is often done asking them to choose between lotteries with different costs and expected utilities. Betting interpretation of subjective probability."
  },
  {
    "objectID": "pages/decision_theory.html#bayesian-decision-theory",
    "href": "pages/decision_theory.html#bayesian-decision-theory",
    "title": "Decision theory",
    "section": "Bayesian decision theory",
    "text": "Bayesian decision theory\n\nBayesian Belief Network\nWet grass - Rain- Sprinkler -Umbrella\nI will demonstrate BBN and influence diagram in genie\n\n\nBayesian decision analysis example in stan\nhttps://mc-stan.org/docs/stan-users-guide/decision-analysis.html"
  },
  {
    "objectID": "pages/conjugate_models.html",
    "href": "pages/conjugate_models.html",
    "title": "Conjugate models",
    "section": "",
    "text": "We say that \\(p(\\pi)\\) is a conjugate prior for \\(L(\\pi,y)\\) if the posterior,\n\\(p(\\pi|y)\\), is from the same model family as the prior.\nThe prior is conjugate with respect to a particular likelihood function.\nThis property is called “conjugacy” and was introduced by Raiffa & Schlaifer (2000), first edition published in 1961.\nConjugate models are still useful. They are used to calculate probability intervals, for updating categorical nodes in binary Bayesian networks.\nThey are limited to simple Bayesian models.\nRaiffa H, Schlaifer R. 2000. Applied statistical decision theory. Wiley classics library ed. New York: Wiley."
  },
  {
    "objectID": "pages/conjugate_models.html#conjugate-model",
    "href": "pages/conjugate_models.html#conjugate-model",
    "title": "Conjugate models",
    "section": "",
    "text": "We say that \\(p(\\pi)\\) is a conjugate prior for \\(L(\\pi,y)\\) if the posterior,\n\\(p(\\pi|y)\\), is from the same model family as the prior.\nThe prior is conjugate with respect to a particular likelihood function.\nThis property is called “conjugacy” and was introduced by Raiffa & Schlaifer (2000), first edition published in 1961.\nConjugate models are still useful. They are used to calculate probability intervals, for updating categorical nodes in binary Bayesian networks.\nThey are limited to simple Bayesian models.\nRaiffa H, Schlaifer R. 2000. Applied statistical decision theory. Wiley classics library ed. New York: Wiley."
  },
  {
    "objectID": "pages/conjugate_models.html#beta-binomial",
    "href": "pages/conjugate_models.html#beta-binomial",
    "title": "Conjugate models",
    "section": "Beta-Binomial",
    "text": "Beta-Binomial\nObservable: number of successes \\(Y\\) out of \\(N\\) independent trials\nObservations(data): \\(y,n\\) (random sample from \\(Y\\) where \\(N=n\\))\nData generating process: \\(Y|\\pi,N \\sim Bin(N,\\pi)\\)\n\\[p(y|\\pi,n) = \\frac{n!}{y!(n-y)!}=\\pi^y(1-\\pi)^{n-y}\\]\nParameter: \\(\\pi\\)\nLikelihood:\n\\[L(\\pi,y,n) = \\frac{n!}{y!(n-y)!}=\\pi^y(1-\\pi)^{n-y}\\]\nlog likelihood\n\\[l(\\pi,y,n) = \\log L(\\pi,y,n) = \\log n! - \\log y! - \\log (n-y)! + y \\log \\pi + (n-y) \\log (1-\\pi)\\]\nSimplification by dropping constant that do not depend on parameter\n\\(l(\\pi,y,n) \\propto y \\log \\pi + (n-y) \\log (1-\\pi)\\)\nPrior: \\(\\pi \\sim Beta(\\alpha,\\beta)\\)\nHyper-parameters: \\(\\alpha\\), \\(\\beta\\)\nPosterior:: \\(\\pi|y,n \\sim Beta(\\alpha+y,\\beta+n-y)\\)\n\nImpact on posterior from prior and data\n\n\n\n\n\n\n\n\n\n\n\nReparameterisation\nData generating process: \\(Y|\\pi,N \\sim Bin(N,\\pi)\\)\nLet us look at an alternative parameterisation of the beta distribution\nLet \\(\\alpha=ts\\) and \\(\\beta=(1-t)s\\)\nThe new parameters \\(t\\) and \\(s\\) can be seen as expected relative frequency and “sample size”, respectively.\nPrior: \\(\\pi \\sim Beta(ts,(1-t)s)\\)\nHyper-parameters: \\(t\\), \\(s\\)\nPosterior: \\(\\pi|y,n \\sim Beta(ts+y,(1-t)s+n-y)\\)\n\n\nBayesian learning - Sequential updating\nBayesian inference can be done sequentially, by using the posterior in a previous step as prior in the next step\nPrior step 1: \\(\\pi|s,t \\sim Beta(ts,(1-t)s)\\)\nPosterior step 1: \\(\\pi|y_1,n_1,s_1,t_1 \\sim Beta(t_1s_1+y_1,(1-t_1)s_1+n_1-y_1)\\)\nPosterior expected relative frequency is\n\\[\\frac{t_1s_1+y_1}{t_1s_1+y_1+(1-t_1)s_1+n_1-y_1}=\\frac{t_1s_1+y_1}{s_1+n_1}\\]\nPrior step 2: \\(\\pi|s_2,t_2 \\sim Beta(t_2s_2,(1-t_2)s_2)\\)\nHyperparameters are the expected relative frequency \\(t_2=\\frac{t_1s_1+y_1}{s_1+n_1}\\) and “sample size” \\(s_2 = s_1+n_1\\)\nPosterior step 2: \\(\\pi|y_2,n_2,s_2,t_2 \\sim Beta(t_2s_2+y_2,(1-t_2)s_2+n_2-y_2)\\)\nHyperparameters for step 3 are the expected relative frequency \\(t_3=\\frac{t_2s_2+y_2}{s_2+n_2}=\\frac{t_1s_1 + y_1 + y_2}{s_1+n_1+n_2}\\) and “sample size” \\(s_3 = s_2+n_2=s_1+n_1+n_2\\)\nThis also demonstrates the property of data-order invariance which states that if data is conditionally independent on the model, the order of updating has no effect on the final posterior.\n\n\nParametric inference\nIs it possible to test hypothesis in Bayesian analysis?\n\nBayes factor\nBayesian p-value\nBayesian confidence interval\nBayesian model selection\n\nUsing observed data to choose between two probabilistic models, \\(M_0\\) and \\(M_1\\).\n\\[\\underbrace{\\frac{p(M_1|data)}{p(M_0|data)}}_{\\text{posterior ratio}}=\\underbrace{\\frac{p(M_1)}{p(M_0)}}_{\\text{prior ratio}}\\underbrace{\\frac{p(data|M_1)}{p(data|M_0)}}_{\\text{bayes factor}}\\]\nhttps://www.statlect.com/fundamentals-of-statistics/posterior-odds-ratio\nUsing observed data to choose between two probabilistic models, \\(M_0\\) and \\(M_1\\) that differ in complexity. For example, consider teh binomial model: \\(M_0\\) could be that the parameter \\(\\pi\\) takes a specific value \\(\\pi_0\\), whereas \\(M_1\\) is that it can be any value in the interval \\([0,1]\\).\nThe probability for data under \\(M_0\\), \\(p(data|M_0)\\), is found by using \\(\\pi=\\pi_0\\) in the probabilistic model for data.\nThe probability for data under \\(M_0\\), \\(p(data|M_1)\\) is found by specifying a prior for \\(\\pi\\), do Bayesian updating, and use the posterior \\(\\pi|data\\) to calcualte the expected probability for data under \\(M_1\\)\n\\[p(data|M_1) = \\int_\\infty^\\infty p(data|\\theta,M_1)p(\\theta|M_1)d\\theta\\]"
  },
  {
    "objectID": "pages/conjugate_models.html#conjugate-models-and-the-exponential-family",
    "href": "pages/conjugate_models.html#conjugate-models-and-the-exponential-family",
    "title": "Conjugate models",
    "section": "Conjugate models and the exponential family",
    "text": "Conjugate models and the exponential family\nAnalytic results for the posterior distribution can always be obtained for a class of distributions known as exponential family distributions, provided that conjugate priors are used.\nExponential family distributions can be written in the form\n\\[p(\\mathbf{y}|\\mathbf{\\eta})=f(\\mathbf{y})\\exp \\left[\\mathbf{\\eta}^T\\mathbf{s(y)} + \\psi(\\mathbf{\\eta})\\right]\\] where \\(\\mathbf{\\eta}\\) is a vector of natural parameters, \\(f(\\mathbf{y})\\) is an arbitrary function that depends only on \\(\\mathbf{y}\\), \\(\\mathbf{s(y)}\\) is a vector containing the sufficient statistics for the data \\(\\mathbf{y}\\), and \\(\\psi(\\mathbf{\\eta})\\) is the logarithm of the normalizing constant.\nFor example\n\\(\\eta = \\log \\frac{\\theta}{1-\\theta}\\)\n\\(\\psi(\\eta) = \\log (1+\\exp(\\eta))=-\\log (1-\\theta)\\)\nFor any exponential family distribution, there is a corresponding family of conjugate priors with \\(p(\\mathbf{\\eta}|\\mathbf{y}) \\propto \\exp \\left[ \\mathbf{\\eta}^T\\nu + \\lambda \\psi(\\mathbf{\\eta})\\right]\\).\nConjugacy can be demonstrated by observing that the posterior is given by\n\\(p(\\mathbf{\\eta}|\\mathbf{y}) \\propto p(\\mathbf{y}|\\mathbf{\\eta})p(\\mathbf{\\eta})\\)\n\nNormal-Normal conjugate model\nObservable: \\(Y\\)\nObservations(data): \\(\\mathbf{y}=(y_1,\\ldots,y_n)\\) (random sample from \\(Y\\))\nData generating process: \\(Y|\\mu,\\sigma \\sim N(\\mu,\\sigma)\\)\n\\[p(\\mathbf{y}|\\mu,\\sigma) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp \\left[-\\frac{(y_i-\\mu)^2}{2\\sigma^2} \\right]\\]\nParameters: \\(\\mu\\), \\(\\sigma\\) (we assume \\(\\sigma\\) is known)\nLikelihood:\n\\[L(\\mu,\\mathbf{y}) \\propto \\prod \\exp \\left[-\\frac{(y_i-\\mu)^2}{2\\sigma^2} \\right] = \\exp \\left[-\\frac{\\sum(y_i-\\mu)^2}{2\\sigma^2} \\right] = \\exp \\left[-\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n} \\right]\\]\nlog likelihood\n\\[l(\\mu,\\mathbf{y}) = \\log L(\\mu,\\mathbf{y}) \\propto -\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}\\]\nPrior:\n\\[\\mu|\\sigma \\sim N(\\mu_0,\\frac{\\sigma}{\\sqrt{k}})\\]\nHyper-parameters: \\(\\mu_0\\), \\(k\\)\nLet \\(\\bar{y}=\\frac{1}{n}\\sum_{i=1}^n y_i\\) be the sample mean and \\(s^2 = \\frac{1}{n-1}\\sum_{i=1}^n (y_i-\\bar{y})^2\\) be the sample variance.\nPosterior:\n\\[\\mu|\\sigma,\\mathbf{y} \\sim N(\\frac{k\\mu_0+n\\bar{y}}{k+n},\\frac{\\sigma}{\\sqrt{(k+n)}})\\]\n\n\n\nGamma-Normal conjugate model\nObservable: \\(Y\\)\nObservations(data): \\(\\mathbf{y}=(y_1,\\ldots,y_n)\\) (random sample from \\(Y\\))\nData generating process: \\(Y|\\mu,\\sigma \\sim N(\\mu,\\sigma)\\)\n\\[p(\\mathbf{y}|\\mu,\\sigma) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp \\left[-\\frac{(y_i-\\mu)^2}{2\\sigma^2} \\right]\\]\nParameters: \\(\\mu\\), \\(\\sigma\\)\nLikelihood:\n\\[L(\\mu,\\sigma,\\mathbf{y}) = \\prod \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp \\left[-\\frac{(y_i-\\mu)^2}{2\\sigma^2} \\right] = \\left(\\frac{1}{\\sqrt{2\\pi\\sigma}}\\right)^n\\exp   \\left[-\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n} \\right]\\]\nlog likelihood\n\\[l(\\mu,\\sigma,\\mathbf{y}) = \\log L(\\mu,\\sigma,\\mathbf{y}) =-\\frac{n}{2}\\log (\\pi\\sigma) -\\frac{(\\bar{y}-\\mu)^2}{2\\sigma^2/n}\\]\nPrior:\n\\[\\mu|\\sigma \\sim N(\\mu_0,\\frac{\\sigma}{\\sqrt{k}})\\]\n\\[\\frac{1}{\\sigma^2} \\sim \\Gamma (\\alpha_0,\\beta_0)\\]\nHyper-parameters: \\(\\mu_0\\), \\(k\\), \\(\\alpha\\), \\(\\beta\\)\nPosterior:\n\\[\\mu|\\sigma,\\mathbf{y} \\sim N(\\frac{k\\mu_0+n\\bar{y}}{k+n},\\frac{\\sigma}{\\sqrt{(k+n)}})\\]\n\\[\\frac{1}{\\sigma^2}|\\mathbf{y} \\sim \\Gamma (\\alpha_0+\\frac{n}{2},\\beta_0+\\frac{s^2(n-1)}{2}+\\frac{nk}{n+k}\\frac{(\\bar{y}-\\mu_0)^2}{2})\\]\n\n\n\nList of conjugate models\nhttps://en.wikipedia.org/wiki/Conjugate_prior"
  },
  {
    "objectID": "pages/conjugate_models.html#example-from-bayesian-networks",
    "href": "pages/conjugate_models.html#example-from-bayesian-networks",
    "title": "Conjugate models",
    "section": "Example from Bayesian Networks",
    "text": "Example from Bayesian Networks\nBayesian Parameter Estimation in Bayesian Networks (section 17.4 in Koller and Friedman 2009).\nA Bayesian Network can be understood as a probability distribution for data that allows specification of a likelihood. BNs were originally developed for categorical or binary nodes linked with edges into network.\nThe concept was expanded for continuous normally distributed nodes, referred to as Gaussian Networks.\nInference in these networks are of two types:\n\nPredictive inference: calculation of the probability of query variables (a subset of variables in the network) given evidence defined by an instantiation of a subset of variables in the network.\n\n\\[p(\\mathbf{Y}|\\mathbf{E}=\\mathbf{e})\\]\n\nParametric inference: Inference of the parameters in a network. This can be to estimate Conditional Probability Tables (CPTs) or expected values and variances in Gaussian Networks.\n\nParametric inference can be done using maximum likelihood estimation.\nTo perform Bayesian parameter estimation of a Bayesian Network, one has to specify a joint probability distribution of the unknown parameters and observables. Koller and Friedman (2009) refers to it as adding a meta-network for learning. Assumes global parameter independence, i.e. priors for parameters do not depend on each other. This allows taking expectations over parameters when making predictions independently and then combine the results when making predictions.\n\nKoller, D., & Friedman, N. (2009). Probabilistic graphical models: principles and techniques. MIT press. PDF\nDemonstration of implementation of priors in Bayesian Networks\nBayesFusion\nhttps://repo.bayesfusion.com/bayesbox.html"
  },
  {
    "objectID": "pages/conjugate_models.html#monte-carlo-simulation",
    "href": "pages/conjugate_models.html#monte-carlo-simulation",
    "title": "Conjugate models",
    "section": "Monte Carlo simulation",
    "text": "Monte Carlo simulation\nConsider the expected value of a function \\(g\\) of the random variable \\(\\theta\\)\n\\[E(g(\\theta)) = \\int_{-\\infty}^{\\infty} g(\\theta)f(\\theta)d\\theta\\]\nAt best, one can use various approximations of the function to derive the target quantity.\nWhen the number of variables increase, it quickly becomes demanding to calculate the expected value\n\\[E(g(\\theta_1,\\theta_2,\\ldots)) = \\int_{-\\infty}^{\\infty} g(\\theta_1,\\theta_2,\\ldots)f(\\theta_1,\\theta_2,\\ldots)d\\theta_1d\\theta_2\\cdots\\]\nMonte Carlo simulation is a numerical method to approximate functions of random variables or processes.\nMonte Carlo approximation works provided that there exists a finite expected value and variance of the function, i.e. that \\(E(|g(\\mathbf{\\theta})|) &lt; \\infty\\) and \\(V(g(\\mathbf{\\theta})) &lt; \\infty\\)\n\n\n\n\n\n\nSome useful theorems\n\n\n\n\nThe weak law of large numbers\nIf \\(X_1,\\ldots\\) are independent and identically distributed random variables with the same expected value \\(\\mu\\), then the average of the random variables converges to the expected value as the number of variables \\(n\\) goes towards infinity:\n\\[\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i \\overset{p}{\\rightarrow} \\mu\\]\nConvergence in probability \\(p\\) is the same thing to say that the average converges to the value \\(\\mu\\) with probability 1.\n\n\nThe strong law of large numbers\nLet \\(X_1,\\ldots\\) be a sequence of independent and identically distributed random variables where the expected value of the absolute random variable is finite, i.e. \\(E(|X_1|) &lt; \\infty\\). Let \\(E(X_1)=\\mu\\), then the average of the random variables converges to the expected value as the number of variables \\(n\\) goes towards infinity:\n\\[\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i \\overset{a.s.}{\\rightarrow} \\mu\\]\n\\(a.s.\\) means “almost surely”, and is a stronger type of convergence than convergence in probability.\n\n\n\nReflection from Kadane\n\nConjugate analysis is neat mathematically when it works. However, the slightest deviation in the specification of the likelihood or prior would destroy the property of conjugacy. Consequently, these results are interesting but far from a usable platform from which to do analyses.\n\n\nSimilarly, large sample theory is nice, but gives little guidance on how large a sample is required for large sample theory to yield good approximations. Since Bayesian analyses can and do deal with small samples as well as large ones (indeed Bayesians can gracefully make decisions with no data at all, relying on their prior), large sample theory is also quite limited in scope.\n\n\nBecause of these limitations, Bayesians now rely heavily on computational methods to find posterior distributions\n\nKadane, J. B. (2020). Principles of uncertainty 2nd. Chapman and Hall/CRC. PDF"
  },
  {
    "objectID": "pages/conjugate_models.html#reflection-from-kadane",
    "href": "pages/conjugate_models.html#reflection-from-kadane",
    "title": "Conjugate models",
    "section": "Reflection from Kadane",
    "text": "Reflection from Kadane\n\nConjugate analysis is neat mathematically when it works. However, the slightest deviation in the specification of the likelihood or prior would destroy the property of conjugacy. Consequently, these results are interesting but far from a usable platform from which to do analyses.\n\n\nSimilarly, large sample theory is nice, but gives little guidance on how large a sample is required for large sample theory to yield good approximations. Since Bayesian analyses can and do deal with small samples as well as large ones (indeed Bayesians can gracefully make decisions with no data at all, relying on their prior), large sample theory is also quite limited in scope.\n\n\nBecause of these limitations, Bayesians now rely heavily on computational methods to find posterior distributions\n\nKadane, J. B. (2020). Principles of uncertainty 2nd. Chapman and Hall/CRC. PDF"
  },
  {
    "objectID": "pages/Bayesian_GLM.html",
    "href": "pages/Bayesian_GLM.html",
    "title": "Bayesian Generalised Linear Models",
    "section": "",
    "text": "library(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(lme4)\nlibrary(brms)\nlibrary(bayesplot)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "pages/Bayesian_GLM.html#categorical-independent-variables-or-predictors",
    "href": "pages/Bayesian_GLM.html#categorical-independent-variables-or-predictors",
    "title": "Bayesian Generalised Linear Models",
    "section": "Categorical independent variables or predictors",
    "text": "Categorical independent variables or predictors\nA categorical predictor can be treated as a factor (or dummy variable)\n\\[X_1 = \\left\\{ \\begin{array}{lr}\n        1 & \\text{if category A}\\\\\n        0 & \\text{if category not A}\n        \\end{array}\\right.\\]\nA categorical predictor generates one regression model per level of the variable\n\\[\\beta_0+\\beta_1x_{1} = \\left\\{ \\begin{array}{lr}\n        \\beta_0+\\beta_1 & \\text{if } x_1=1\\\\\n        \\beta_0 & \\text{if } x_1=0\n        \\end{array}\\right.\\]"
  },
  {
    "objectID": "pages/Bayesian_GLM.html#the-basic-linear-model",
    "href": "pages/Bayesian_GLM.html#the-basic-linear-model",
    "title": "Bayesian Generalised Linear Models",
    "section": "The basic linear model",
    "text": "The basic linear model\nThe model\n\\[y_i=\\beta_0+\\beta_1x_{i1}+\\ldots+\\beta_px_{ip}+\\varepsilon_i\\]\nwhere \\(\\varepsilon_i\\sim N(0,\\sigma^2)\\)\ncan alternatively be written as\n\\[Y|x_i\\sim N(\\beta_0+\\beta_1x_{i1}+\\ldots+\\beta_px_{ip},\\sigma)\\]\nor\n\\[Y|x_i\\sim N(\\mu(x_i|\\beta_0,\\beta_1,\\ldots,\\beta_p),\\sigma)\\]\nwhere \\(\\mu(x_i|\\beta_0,\\beta_1,\\ldots,\\beta_p):=E(Y|x_i,\\beta_0,\\beta_1,\\ldots,\\beta_p)\\) is the expected value of \\(Y\\) for \\(x=x_i\\) and parameters \\(\\beta_0,\\ldots,\\beta_p\\).\nIn this model, the response variable \\(Y\\) is continuous and the model error is normally distributed with equal variance \\(\\sigma^2\\).\n\nFor notation, I sometimes lump all parameters into one \\(\\theta=(\\beta_0,\\beta_1,\\ldots,\\beta_p,\\sigma)\\).\n\n\n\n\n\n\n\nNote\n\n\n\nFor certain statistical tests, one has to assume that errors/residuals are independent, i.e. that observations \\((y_i,x_i)\\) are independent of each other."
  },
  {
    "objectID": "pages/Bayesian_GLM.html#from-normal-to-any-distribution-family-for-the-response-variable",
    "href": "pages/Bayesian_GLM.html#from-normal-to-any-distribution-family-for-the-response-variable",
    "title": "Bayesian Generalised Linear Models",
    "section": "From normal to any distribution family for the response variable",
    "text": "From normal to any distribution family for the response variable\nWhat if the response variable is\n\ncategorical, e.g. succeed/fail or gene expressions, or\ndiscrete, e.g. a count of the number of individuals,\nor some other continuous distribution?"
  },
  {
    "objectID": "pages/Bayesian_GLM.html#logistic-regression",
    "href": "pages/Bayesian_GLM.html#logistic-regression",
    "title": "Bayesian Generalised Linear Models",
    "section": "Logistic regression",
    "text": "Logistic regression\nConsider a response variable with two categories, success or failure.\n\\[Y = \\left\\{ \\begin{array}{lr}\n        1 & \\text{if success}\\\\\n        0 & \\text{if failure}\n        \\end{array}\\right.\\]\nThe probability model for the response variable for a given value on the predictor can be a Bernoulli distribution\n\\[Y|x_i \\sim Be(p(x_i))\\] where the logarithm of the odds-ratio (logodds or logit) of the probability-parameter in the Bernoulli-distribution can be written as a linear function of the predictors\n\\[log\\left(\\frac{p(x_i)}{1-p(x_i)}\\right) = \\underbrace{\\beta_0+\\beta_1x_{i1}+\\ldots+\\beta_px_{ip}}_{linear \\ term}\\]\nThis relationship can be transformed into\n\\[\\frac{p(x_i)}{1-p(x_i)} = e^{\\beta_0+\\beta_1x_{i1}+\\ldots+\\beta_px_{ip}}\\] and finally into an expression where the probability-parameter is a logistic function of the linear term:\n\\[p(x_i)=\\frac{e^{\\beta_0+\\beta_1x_{i1}+\\ldots+\\beta_px_{ip}}}{1+e^{\\beta_0+\\beta_1x_{i1}+\\ldots+\\beta_px_{ip}}}\\]\nNote that \\(E(Y|x_i)=p(x_i)\\)\n\nA link function is a function that transforms the linear term into the expected value for the response variable\n\nThis model for binary response is therefore known as logistic regression."
  },
  {
    "objectID": "pages/Bayesian_GLM.html#glm-binomial-response-variable",
    "href": "pages/Bayesian_GLM.html#glm-binomial-response-variable",
    "title": "Bayesian Generalised Linear Models",
    "section": "GLM Binomial response variable",
    "text": "GLM Binomial response variable\nLet the \\(i\\)th observation be the number of successful trials among \\(n_i\\) independent trials. The response variable can be modelled by a Binomial distribution\n\\[Y|x_i\\sim Bin(n_i,p(x_i))\\]\nThe expected value of the proportion of successes is \\(E(Y|x_i)=\\frac{n_ip(x_i)}{n_i}=p(x_i)\\).\nA Binomial GLM is created by transforming the expected value with the logit link function as before into the linear model.\n\\[ \\text{logit}(p(x_i)) = \\log(p(x_i) / (1 - p(x_i))) = \\beta_0+\\beta_1x_{i1}+\\ldots+\\beta_px_{ip}\\]\n\nA logistic regression is a special case of Binomial GLM when there is only one trial per observation, i.e. n_i = 1."
  },
  {
    "objectID": "pages/Bayesian_GLM.html#glm-poisson-response-variable",
    "href": "pages/Bayesian_GLM.html#glm-poisson-response-variable",
    "title": "Bayesian Generalised Linear Models",
    "section": "GLM Poisson response variable",
    "text": "GLM Poisson response variable\nConsider a discrete response variable that is a count where the outcome space consists of natural numbers starting from 0, i.e. \\(0, 1, 2, \\ldots\\) with no upper bound.\nA Poisson distribution is a suitable probability distribution of this type of response variable if the counts come from an even process where events occur with a fixed intensity, \\(\\lambda\\), events are independent, and events cannot occur at the same time.\nLet the expected value of the response \\(Y\\) be a function of the linear model of predictors\n\\[\\lambda(x_i)=e^{\\beta_0+\\beta_1x_{i1}+\\ldots+\\beta_px_{ip}}\\]\nWhen we log the expected value we get\n\\[\\log(\\lambda(x_i))=\\beta_0+\\beta_1x_{i1}+\\ldots+\\beta_px_{ip}\\] A Poisson GLM has log as the link function\n\\[Y|x_i\\sim Po(\\lambda(x_i))\\]"
  },
  {
    "objectID": "pages/Bayesian_GLM.html#glm-hurdle-model",
    "href": "pages/Bayesian_GLM.html#glm-hurdle-model",
    "title": "Bayesian Generalised Linear Models",
    "section": "GLM hurdle model",
    "text": "GLM hurdle model"
  },
  {
    "objectID": "pages/Bayesian_GLM.html#why-is-hierarchical-modelling-important",
    "href": "pages/Bayesian_GLM.html#why-is-hierarchical-modelling-important",
    "title": "Bayesian Generalised Linear Models",
    "section": "Why is hierarchical modelling important?",
    "text": "Why is hierarchical modelling important?\nIgnoring dependencies, result in underestimation of standard error and possible lower p-values in frequentist hypothesis testing.\nAn appropriate implementation of the hierarchical structures in data can reduce error in predictions, and increase the ability for the model to estimate and test associations.\nAn alternative would be to estimate one function per group of independent samples, but that leaves us with several models with possible poorer performances per model. With this in mind, hierarchical modeling can be used to build one model estimated from all data, and allow for sharing information between groups of data.\nWhen basic assumptions are not met, there is something wrong with the model. Adding a hierarchical structure is one way to improve a model for inference."
  },
  {
    "objectID": "pages/Bayesian_GLM.html#example-penguins",
    "href": "pages/Bayesian_GLM.html#example-penguins",
    "title": "Bayesian Generalised Linear Models",
    "section": "Example Penguins",
    "text": "Example Penguins\nHere is an example of results will drastically change when groups are considered in an analysis.\n\ndb &lt;- penguins %&gt;% \n  filter(!is.na(flipper_length_mm), !is.na(bill_length_mm), !is.na(body_mass_g))\n\n\nThe palmerpenguins data\nThe palmerpenguins data contains size measurements for three penguin species observed on three islands in the Palmer Archipelago, Antarctica. This data set is being used for education of statistics and data science.\n\n\n\nAssociation between bill length and bill depth\nLet \\(y=\\text{\"Bill depth in mm\"}\\) and \\(x=\\text{\"Bill length in mm\"}\\)\nWe model their linear association by a simple linear regression\n\\[y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\]\nwhere \\(\\varepsilon_i \\sim N(0,\\sigma)\\) for all pairs of observations \\(i=1,\\ldots,n\\)\n\n\n\n\n\n\nCaution\n\n\n\nWhat could be a potential weakness in choosing a linear regression model for testing the association between the two variables?\nIn this course, we expect that you can account for the assumptions behind a linear regression model.\n\n\n\nggplot2::theme_set(ggplot2::theme_minimal())\n\n\nggplot(data = db,\n                         aes(x = bill_length_mm,\n                             y = bill_depth_mm)) +\n  geom_point() +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(title = \"Penguin bill dimensions\",\n       subtitle = \"at Palmer Station LTER\",\n       x = \"Bill length (mm)\",\n       y = \"Bill depth (mm)\") +\n  theme(plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\") +\n  geom_smooth(method = \"lm\", formula = 'y ~ x', se = FALSE, color = \"gray50\")\n\n\n\n\n\n\n\n\n\nmod &lt;- lm(bill_depth_mm ~ bill_length_mm,data = db)\ns &lt;- summary(mod)\n\nThe linear association (the slope parameter) is estimated to be negative (-0.085) and significantly different from zero (95th \\(CI_{\\beta_1} = (-0.1225253,-0.0475173)\\), p-value &lt; 0.05).\n\ns$coefficients\n\n                  Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept)    20.88546832 0.84388321 24.749240 4.715137e-78\nbill_length_mm -0.08502128 0.01906694 -4.459093 1.119662e-05\n\n\n\nggplot(mod, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, col = 'darkred', linetype = \"dashed\")\n\nWarning: `fortify(&lt;lm&gt;)` was deprecated in ggplot2 4.0.0.\nℹ Please use `broom::augment(&lt;lm&gt;)` instead.\nℹ The deprecated feature was likely used in the ggplot2 package.\n  Please report the issue at &lt;https://github.com/tidyverse/ggplot2/issues&gt;.\n\n\n\n\n\n\n\n\n\n\n\nResidual analysis\n\nCheck assumption of independence and equal variance of residuals\n\n\nggplot(mod, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, col = 'darkred', linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\nCheck assumption of normally distributed residuals\n\n\nggplot(mod, aes(sample = .resid)) +\nstat_qq() + stat_qq_line(col='darkred',linetype='dashed') +\n  xlab('theoretical quantiles') +\n  ylab('empirical (sample) quantiles') +\n  ggtitle(\"Quantile-Quantile plot for the Normal distribution\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIs it justified to make the assumptions that the residuals are independent identically and normally distributed?"
  },
  {
    "objectID": "pages/Bayesian_GLM.html#a-hierarhical-model-considering-groups-in-data",
    "href": "pages/Bayesian_GLM.html#a-hierarhical-model-considering-groups-in-data",
    "title": "Bayesian Generalised Linear Models",
    "section": "A hierarhical model considering groups in data",
    "text": "A hierarhical model considering groups in data\nFrom the analysis above, we conclude that there is something odd with the model. It odd that there should be a negative association between the length and depth of a bill, and the residual analysis induces some discomfort in making conclusions from the model.\nThe data material consists of observations from three species, which constitute three groups where one can expect that the variation between groups is larger than the variation within groups. What if the relationship between bill length and bill depth looks different for different species?\n\nLet us investigate by visualising the data where we separate the observations from the three groups. Here the visualisation is made by fitting a linear model per group.\n\nbill_len_dep &lt;- ggplot(data = db,\n                         aes(x = bill_length_mm,\n                             y = bill_depth_mm,\n                             group = species)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 3,\n             alpha = 0.8) +\n  geom_smooth(method = \"lm\", formula = 'y ~ x',se = FALSE, aes(color = species)) +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(title = \"Penguin bill dimensions\",\n       subtitle = \"Bill length and depth for Adelie, Chinstrap and Gentoo Penguins at Palmer Station LTER\",\n       x = \"Bill length (mm)\",\n       y = \"Bill depth (mm)\",\n       color = \"Penguin species\",\n       shape = \"Penguin species\") +\n  theme(legend.position = c(0.85, 0.15),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")\n\nbill_len_dep\n\n\n\n\n\n\n\n\nHere we can note that within each group now there is a positive linear association between bill length and bill depth.\n\nSimpson’s paradox, or the Yule–Simpson effect, is a phenomenon in probability and statistics, in which a trend appears in several different groups of data but disappears or reverses when these groups are combined. It is sometimes given the descriptive title reversal paradox or amalgamation paradox. data-to-viz.com"
  },
  {
    "objectID": "pages/Bayesian_GLM.html#a-linear-model-with-random-and-fixed-effects",
    "href": "pages/Bayesian_GLM.html#a-linear-model-with-random-and-fixed-effects",
    "title": "Bayesian Generalised Linear Models",
    "section": "A linear model with random and fixed effects",
    "text": "A linear model with random and fixed effects\nHere is one way to model hierarchies in data.\nLet \\(y_{ij}\\) be the \\(i\\)th observation from species \\(j\\) given a fixed \\(x_{ij}\\), where \\(i=1,\\ldots,n\\) and \\(j=1,2,3\\).\n\\[y_{ij} = \\beta_{0j} + \\beta_1 x_{ij} + \\varepsilon_{ij}\\]\nwhere \\(E(\\varepsilon_{ij})=0\\) and \\(V(\\varepsilon_{ij})=\\sigma^2\\)\nThe variance parameter \\(\\sigma^2\\) is the variation in the model residuals.\n\\[y_{ij} = \\beta_{0} + u_{j} + \\beta_1 x_{ij} + \\varepsilon_{ij}\\]\nwhere \\(E(u_j)=0\\) and \\(V(u_j)=\\tau^2\\).\nNow we have a model where we divide the variance into variance due to random error for the model and variance due to variation between groups.\nThe parameter \\(\\beta_1\\) is a fixed effect because the slope is the same for all groups.\nThe term \\(u_j\\) is called a random effect because it takes different values for different groups \\(j = 1,2,3\\) (we have three species of penguins).\nWe can also assume the \\(u_j \\sim N(0,\\tau^2)\\)\nThe variance parameter \\(\\tau^2\\) is between-group heterogeneity. Here it denotes the variance in the random intercepts.\nA model with fixed and random effects (a.k.a a linear mixed model) can be estimated by maximum likelihood or Bayesian inference.\n\n\n\n\n\n\nNote\n\n\n\nIn some cases, it can be justified to consider that the slope might differ between groups. If so, a random effect on the slope can be added.\n\n\n\nMaximum likelihood estimation\nHere I have applied REstricted Maximum Likelihood (REML). The way of specifying the models using user-friendly software is\n\nrmod &lt;- lme4::lmer(bill_depth_mm~bill_length_mm + (1|species), data = db)\n\n\nsummary(rmod)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: bill_depth_mm ~ bill_length_mm + (1 | species)\n   Data: db\n\nREML criterion at convergence: 959.5\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5632 -0.7210 -0.0507  0.5814  3.7654 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n species  (Intercept) 6.6319   2.5753  \n Residual             0.9089   0.9533  \nNumber of obs: 342, groups:  species, 3\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     8.28702    1.68309   4.924\nbill_length_mm  0.19898    0.01747  11.390\n\nCorrelation of Fixed Effects:\n            (Intr)\nbll_lngth_m -0.468\n\n\n\n\nResidual analysis\n\nCheck assumption of independence and equal variance of residuals\n\n\ndf_res &lt;- data.frame(.fitted=fitted(rmod),.resid = resid(rmod), species = db$species)\nggplot(df_res, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, col = 'darkred', linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\nCheck assumption of normally distributed residuals\n\n\nggplot(df_res, aes(sample = .resid)) + \nstat_qq() + stat_qq_line(col='darkred',linetype='dashed') +\n  xlab('theoretical quantiles') +\n  ylab('empirical (sample) quantiles') +\n  ggtitle(\"Quantile-Quantile plot for the Normal distribution\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNow it looks better !\n\n\n\n\nTesting the fixed effect in the hierarhical model\nI am interested in testing if there is a linear association.\nI can test using a confidence interval\n\nci &lt;- confint(rmod)\n\nA 95th confidence interval of the slope parameter based on the profile likelihood method is derived to be \\(CI_{\\beta_1}= (0.1641772,0.2328453)\\), i.e. a positive linear association that is statistically different from zero at the 5%’s significance level.\n\nWhen my model is estimated with a restricted maximum likelihood, using a likelihood ratio test can be wrong since the likelihoods are conditional on different values of a so called nuisance parameter.\nThen I can implement the maximum likelihood without a restriction (which can be problematic for the optimisation), or\nImplement the hierarchical model in a Bayesian framework and test using suitable methods therein"
  },
  {
    "objectID": "pages/Bayesian_GLM.html#bayesian-model-specification",
    "href": "pages/Bayesian_GLM.html#bayesian-model-specification",
    "title": "Bayesian Generalised Linear Models",
    "section": "Bayesian model specification",
    "text": "Bayesian model specification\nA Bayesian specification of the model made in “tilde”-format can be\n\nLikelihood\n\n\\[Y_{ij}|\\beta_{0},\\beta_1,\\sigma,x \\sim N(\\beta_{0} + u_j + \\beta_1 x_{ij},\\sigma^2)\\]\n\\[u_j|\\tau \\sim N(0,\\tau)\\]\n\nThe prior is derived based on the following marginal distributions\n\n\\[\\beta_0\\sim N(\\mu_{\\beta_0},\\sigma_{\\beta_0})\\] \\[\\beta_1\\sim N(\\mu_{\\beta_1},\\sigma_{\\beta_1})\\]\n\\[\\tau \\sim \\Gamma(a_{\\tau},b_{\\tau})\\]\n\\[\\sigma \\sim \\Gamma(a_{\\sigma},b_{\\sigma})\\]\nwhere \\(\\mu_{\\beta_0},\\sigma_{\\beta_0},\\mu_{\\beta_1},\\sigma_{\\beta_1},a_{\\tau},b_{\\tau},a_{\\sigma},b_{\\sigma}\\) are hyper-parameters."
  },
  {
    "objectID": "pages/Bayesian_GLM.html#bayesian-penguins",
    "href": "pages/Bayesian_GLM.html#bayesian-penguins",
    "title": "Bayesian Generalised Linear Models",
    "section": "Bayesian penguins",
    "text": "Bayesian penguins\n\nbmod &lt;- brms::brm(bill_depth_mm~bill_length_mm + (1|species), data = db, family=gaussian(), chains = 4,\n  iter = 1000, warmup = 500)\n\nCompiling Stan program...\n\n\nWARNING: Rtools is required to build R packages, but is not currently installed.\n\nPlease download and install the appropriate version of Rtools for 4.5.2 from\nhttps://cran.r-project.org/bin/windows/Rtools/.\n\n\nTrying to compile a simple C file\n\n\nRunning \"C:/PROGRA~1/R/R-45~1.2/bin/x64/Rcmd.exe\" SHLIB foo.c\nusing C compiler: 'gcc.exe (GCC) 14.3.0'\ngcc  -I\"C:/PROGRA~1/R/R-45~1.2/include\" -DNDEBUG   -I\"C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/Rcpp/include/\"  -I\"C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/RcppEigen/include/\"  -I\"C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/RcppEigen/include/unsupported\"  -I\"C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/BH/include\" -I\"C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/StanHeaders/include/src/\"  -I\"C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/StanHeaders/include/\"  -I\"C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/RcppParallel/include/\" -DRCPP_PARALLEL_USE_TBB=1 -I\"C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include \"C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/StanHeaders/include/stan/math/prim/fun/Eigen.hpp\"  -std=c++1y    -I\"C:/rtools45/x86_64-w64-mingw32.static.posix/include\"      -O2 -Wall -std=gnu2x  -mfpmath=sse -msse2 -mstackrealign   -c foo.c -o foo.o\ncc1.exe: warning: command-line option '-std=c++14' is valid for C++/ObjC++ but not for C\nIn file included from C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/RcppEigen/include/Eigen/Core:19,\n                 from C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/RcppEigen/include/Eigen/Dense:1,\n                 from C:/Users/ekol-usa/AppData/Local/R/win-library/4.5/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22,\n                 from &lt;command-line&gt;:\nC:/Users/ekol-usa/AppData/Local/R/win-library/4.5/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory\n  679 | #include &lt;cmath&gt;\n      |          ^~~~~~~\ncompilation terminated.\nmake: *** [C:/PROGRA~1/R/R-45~1.2/etc/x64/Makeconf:289: foo.o] Error 1\n\n\nWARNING: Rtools is required to build R packages, but is not currently installed.\n\nPlease download and install the appropriate version of Rtools for 4.5.2 from\nhttps://cran.r-project.org/bin/windows/Rtools/.\n\n\nStart sampling\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000215 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.15 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:   1 / 1000 [  0%]  (Warmup)\nChain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)\nChain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)\nChain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)\nChain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)\nChain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)\nChain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)\nChain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)\nChain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)\nChain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)\nChain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)\nChain 1: Iteration: 1000 / 1000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.292 seconds (Warm-up)\nChain 1:                1.088 seconds (Sampling)\nChain 1:                2.38 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.3e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.43 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:   1 / 1000 [  0%]  (Warmup)\nChain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)\nChain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)\nChain 2: Iteration: 300 / 1000 [ 30%]  (Warmup)\nChain 2: Iteration: 400 / 1000 [ 40%]  (Warmup)\nChain 2: Iteration: 500 / 1000 [ 50%]  (Warmup)\nChain 2: Iteration: 501 / 1000 [ 50%]  (Sampling)\nChain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)\nChain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)\nChain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)\nChain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)\nChain 2: Iteration: 1000 / 1000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 1.608 seconds (Warm-up)\nChain 2:                1.509 seconds (Sampling)\nChain 2:                3.117 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 3.5e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:   1 / 1000 [  0%]  (Warmup)\nChain 3: Iteration: 100 / 1000 [ 10%]  (Warmup)\nChain 3: Iteration: 200 / 1000 [ 20%]  (Warmup)\nChain 3: Iteration: 300 / 1000 [ 30%]  (Warmup)\nChain 3: Iteration: 400 / 1000 [ 40%]  (Warmup)\nChain 3: Iteration: 500 / 1000 [ 50%]  (Warmup)\nChain 3: Iteration: 501 / 1000 [ 50%]  (Sampling)\nChain 3: Iteration: 600 / 1000 [ 60%]  (Sampling)\nChain 3: Iteration: 700 / 1000 [ 70%]  (Sampling)\nChain 3: Iteration: 800 / 1000 [ 80%]  (Sampling)\nChain 3: Iteration: 900 / 1000 [ 90%]  (Sampling)\nChain 3: Iteration: 1000 / 1000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 1.4 seconds (Warm-up)\nChain 3:                1.375 seconds (Sampling)\nChain 3:                2.775 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 5.4e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.54 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:   1 / 1000 [  0%]  (Warmup)\nChain 4: Iteration: 100 / 1000 [ 10%]  (Warmup)\nChain 4: Iteration: 200 / 1000 [ 20%]  (Warmup)\nChain 4: Iteration: 300 / 1000 [ 30%]  (Warmup)\nChain 4: Iteration: 400 / 1000 [ 40%]  (Warmup)\nChain 4: Iteration: 500 / 1000 [ 50%]  (Warmup)\nChain 4: Iteration: 501 / 1000 [ 50%]  (Sampling)\nChain 4: Iteration: 600 / 1000 [ 60%]  (Sampling)\nChain 4: Iteration: 700 / 1000 [ 70%]  (Sampling)\nChain 4: Iteration: 800 / 1000 [ 80%]  (Sampling)\nChain 4: Iteration: 900 / 1000 [ 90%]  (Sampling)\nChain 4: Iteration: 1000 / 1000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 1.34 seconds (Warm-up)\nChain 4:                1.588 seconds (Sampling)\nChain 4:                2.928 seconds (Total)\nChain 4: \n\n\nWarning: There were 6 divergent transitions after warmup. See\nhttps://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\nto find out why this is a problem and how to eliminate them.\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\n\nsummary(bmod)\n\nWarning: There were 6 divergent transitions after warmup. Increasing\nadapt_delta above 0.8 may help. See\nhttp://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n\n\n Family: gaussian \n  Links: mu = identity \nFormula: bill_depth_mm ~ bill_length_mm + (1 | species) \n   Data: db (Number of observations: 342) \n  Draws: 4 chains, each with iter = 1000; warmup = 500; thin = 1;\n         total post-warmup draws = 2000\n\nMultilevel Hyperparameters:\n~species (Number of levels: 3) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     2.80      1.14     1.32     5.71 1.02      566      803\n\nRegression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept          8.40      1.55     5.63    11.60 1.00      613      661\nbill_length_mm     0.20      0.02     0.16     0.23 1.00     1567      998\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.96      0.04     0.89     1.04 1.00     1460     1080\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nplot(bmod)\n\n\n\n\n\n\n\n\n\nbrms::mcmc_plot(bmod,type=\"trace\")\n\n\n\n\n\n\n\n\n\nbrms::mcmc_plot(bmod,pars=c(\"b_Intercept\",\"b_bill_length_mm\"),type=\"scatter\")\n\nWarning: Argument 'pars' is deprecated. Please use 'variable' instead.\n\n\n\n\n\n\n\n\n\n\n# investigate model fit\nloo(bmod)\n\n\nComputed from 2000 by 342 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -472.3 14.6\np_loo         5.3  0.7\nlooic       944.6 29.1\n------\nMCSE of elpd_loo is 0.1.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.6, 1.0]).\n\nAll Pareto k estimates are good (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\npp_check(bmod)\n\nUsing 10 posterior draws for ppc type 'dens_overlay' by default."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BADT26",
    "section": "",
    "text": "First meeting 2-3 Feb\nDay 1 Monday, 2 Feb 2026 (12-16)\nLundmarkssalen Astronomihuset\nCourse introduction\nLecture with non-computer exercises: Bayesian inference and subjective probability\nReading: BR* (Chapters 1 and 2) and DBDA* (Chapter 2, 4 and 5)\nExercise 1: Probability\nLecture about conjugate models\nReadings: BR* (Chapters 3 and 5) and DBDA* (Chapters 6)\nExercise 2: Conjugate models\nLecture on Bayesian analysis using MCMC\nExercise 3. Write your own MCMC sampler\nDay 2 Tuesday, 3 Feb 09.00 - 14.00\nPufendorf Institute for Advanced Studies\n9.15 Bayesian analysis using MCMC\nReading: BR* (Chapters 6, 7, 8) and DBDA* (Chapter 7)\nExercise 2: Conjugate models Solution\nExercise 3. Write your own MCMC sampler\nShort lecture Introduction to software for MCMC sampling\nShort lecture Predictive performance in Bayesian inference\nExercise 4. Get started with a software for MCMC sampling\n12-13 Lunch\nLecture Generalised Linear Regression models\nReading: BR* (Chapters 9, 10, 11) and DBDA* (Chapter 15)\n14.15 Lecture on Decision theory\nReading: 1* and 2*\n\n\nSecond meeting 24-25 Feb\nMaterial for second meeting to come"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html",
    "href": "pages/Bayesian_inference_subjective_probability.html",
    "title": "Bayesian inference and subjective probability",
    "section": "",
    "text": "Reading: BR* (Chapters 1 and 2) and DBDA* (Chapter 2, 4 and 5)\nContent: Probability, statistical inference, likelihood, priors, Bayes rule, posterior"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#content",
    "href": "pages/Bayesian_inference_subjective_probability.html#content",
    "title": "Bayesian inference and subjective probability",
    "section": "",
    "text": "Reading: BR* (Chapters 1 and 2) and DBDA* (Chapter 2, 4 and 5)\nContent: Probability, statistical inference, likelihood, priors, Bayes rule, posterior"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#classical-probability",
    "href": "pages/Bayesian_inference_subjective_probability.html#classical-probability",
    "title": "Bayesian inference and subjective probability",
    "section": "Classical probability",
    "text": "Classical probability\nConditional probability\n\nIf of the two subsequent events, the probability of the 1st be \\(a/N\\) and the probability of both together be \\(P/N\\), then the probability of the 2nd on the supposition the 1st happens is \\(P/a\\). \\(P(B|A)=P(A \\& B)/P(A)\\)\n\nBayes, hesitantly, concluded that time does not distinguish between the events and therefore that the relationship between \\(A\\) and \\(B\\) is not necessarily causal. \\(P(A|B)P(B)=P(B|A)P(A)\\)\nLaplace’s law of succession\n\nIf an urn contains an infinity of white and black tickets in an unknown ratio, and if p + q tickets are drawn of which p are white and q are black, we ask the probability that in drawing a new ticket from this urn it will be white.\n\nLaplace suggested to replace a single urn of unknown constitution with an infinity of urns of known constitution \\[\\frac{\\int_0^1x^{p+1}(1-x)^qdx}{\\int_0^1x^{p}(1-x)^qdx}=\\frac{p+1}{p+q+2}\\]"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#frequentist-probability",
    "href": "pages/Bayesian_inference_subjective_probability.html#frequentist-probability",
    "title": "Bayesian inference and subjective probability",
    "section": "Frequentist probability",
    "text": "Frequentist probability\nBernoulli (1655-1705) in Ars Conjectandi:\nIf you take a large enough sample, you can be sure, that the proportion of white pebbles you observe in the sample is close to the proportion in the urn (Law of Large Numbers).\n\n“The sample ratio is close to a given urn ratio with a high probability” vs “The urn ratio is close to a given sample ratio with high probability.”\n\n\nFascination with the normal curve and deviations from average (Adolphe Quetelet)\nGalton’s natural selection and eugenics. Reversion (or regression) towards mediocrity in hereditary studies\nPearson - numerical measure of normality \\(\\chi^2\\).\nYoung genius Fischer. Break-off. Animosity and hostility. Fischer’s continuous war with Egon Pearson and Jerzy Nyman.\n\n[1] Clayton (2021) [2] Acree (2021)"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#logical-probability",
    "href": "pages/Bayesian_inference_subjective_probability.html#logical-probability",
    "title": "Bayesian inference and subjective probability",
    "section": "Logical probability",
    "text": "Logical probability\n\nInference is an extension of Boolean algebra with an implication operator \\(A\\implies B\\) (“A implies B”).\nImplication does not assert that either \\(A\\) or \\(B\\) is true, but merely that \\(A\\overline{B}\\) is FALSE, i.e. that \\((\\overline{A}+B)\\) is TRUE. Also can be expressed as \\(A=AB\\): propositions \\(A\\) and \\(AB\\) have the same truth value.\n\nDesiderata for plausibility reasoning:\n\nRepresentation of degrees of plausibility by real numbers;\nQualitative correspondence with common sense;\nConsistency:\n\nIf a conclusion can be reasoned out in more than one way, then every possible way must lead to the same result\nThe robot always takes into account all of the evidence it has relevant to a question. […] the robot is completely nonideological.\nThe robot always represents equivalent states of knowledge by equivalent plausibility assignments.\n\n\nRandomization does not change the state of the world. It alters our knowledge. Mind-projection fallacy.\n[1] Jaynes(2003)"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#logical-probability-1",
    "href": "pages/Bayesian_inference_subjective_probability.html#logical-probability-1",
    "title": "Bayesian inference and subjective probability",
    "section": "Logical probability",
    "text": "Logical probability\n\nRules of plausibility reasoning\n\nThe product rule\n\n\\[p(AB|C)=p(A|C)p(B|AC)=p(B|C)p(A|BC)\\]\n\nThe sum rule\n\n\\[p(A|B)+p(\\overline{A}|B)=1\\]\n\\[p(A+B|C)=p(A|C)+p(B|C)-p(AB|C)\\]\nInterpretation of plausibility\n\\(A \\implies B\\)\n\n\\(B\\) is true, therefore \\(A\\) becomes more plausible\n\\(A\\) is false, therefore \\(B\\) becomes less plausible\n\n[1] Jaynes (2003)"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#subjectivist-probability",
    "href": "pages/Bayesian_inference_subjective_probability.html#subjectivist-probability",
    "title": "Bayesian inference and subjective probability",
    "section": "Subjectivist probability",
    "text": "Subjectivist probability\nBeliefs without actions are abstract. Probabilities can be understood only in the context of an agent (someone making a decision or doing reasoning).\n\nBruno de Finetti (1906-1985)\n\n“PROBABILITY DOES NOT EXIST!”\nInterpretation of probability as personal attitude to uncertainty is inseparable from willingness to take risk\nUnexperienced uncertainty (nothing at stake) is not a real uncertainty\nUncertainty can only be observed (and probabilities can be extracted) from betting behavior\n\n\n\nFrank Ramsey (1903-1930)[1]\n\nProbabilities are subjective. Both prior beliefs and previously experienced frequencies are relevant for decision\nBeliefs can be separated from preferences through the definition of “ethically neutral proposition” (uninfluenced decision)\n\n[1]N-E Sahlin"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#knightian-uncertainty",
    "href": "pages/Bayesian_inference_subjective_probability.html#knightian-uncertainty",
    "title": "Bayesian inference and subjective probability",
    "section": "Knightian uncertainty",
    "text": "Knightian uncertainty\nKnight (1921):\n\nrisk - inherent randomness in the world described by probability\nuncertainty - lack of knowledge. “Uncertainty occurs when we cannot assign values to the probability”\n\nBayes and Knight does not combine!\nIntroduce uncertainty about probabilities e.g. \nImprecise probability theory:\n\nWhat to do when one can not assign a single probability number?\nProbability represented by bounds without any distribution assigned to them (NOT uniform!)\n\nRobust Bayesian approach gives imprecise probabilities\n\nSets of priors or sets of likelihoods\nFind bounds of probabilities when summarising quantities of interest\n\nRelax the strict interpretation of Knight (he admitted that probability can describe uncertainty when there is enough basis to make judgements or Bayesian inferece)\n\nAvoid conflating probabilities defining risk with probabilities expressing uncertainty about risk"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#time-to-reflect",
    "href": "pages/Bayesian_inference_subjective_probability.html#time-to-reflect",
    "title": "Bayesian inference and subjective probability",
    "section": "Time to reflect",
    "text": "Time to reflect\n\nHow can different interpretations of probability affect a scientific discussion or knowledge generating process?\nWhich perspectives on probability have you encountered in you research experience?"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#likelihood",
    "href": "pages/Bayesian_inference_subjective_probability.html#likelihood",
    "title": "Bayesian inference and subjective probability",
    "section": "Likelihood",
    "text": "Likelihood\n\\(p(data|\\text{parameters})\\)\n\nParameters as fixed and data as variable\nData as fixed and parameter as uncertain"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#steps-of-a-bayesian-data-analysis",
    "href": "pages/Bayesian_inference_subjective_probability.html#steps-of-a-bayesian-data-analysis",
    "title": "Bayesian inference and subjective probability",
    "section": "Steps of a Bayesian data analysis",
    "text": "Steps of a Bayesian data analysis\n\nIdentify data relevant to the research question (question/model-first)\nDefine a probabilistic data generating model (linking data to question/model, needed to derive the likelihood)\nSpecify prior for parameters within the model\nUse Bayesian inference to re-allocate credibility across parameter values. Interpret the posterior with respect to the validity of the model.\nCheck that the posterior predictions mimic the data with reasonable accuracy (i.e. make posterior predictive check)"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#parametric-inference-parameter-estimation",
    "href": "pages/Bayesian_inference_subjective_probability.html#parametric-inference-parameter-estimation",
    "title": "Bayesian inference and subjective probability",
    "section": "Parametric inference (parameter estimation)",
    "text": "Parametric inference (parameter estimation)\nInference about parameters are made by summarising the posterior for the quantity of interest.\n\nPosterior mean and variance\nPosterior mode\nPosterior probability interval\nPosterior quantiles (percentiles)\nPropagation of posterior uncertainty into quantities derived from parameters \\(g(\\theta)\\)\n\n\nBayesian p-value\nSometimes, analysts derive a Bayesian “p-value” which is the posterior probability of a null hypothesis. If this probability is small, then the null hypothesis can be rejected. Note that this is a pragmatic approach adopting frequentist terminology and not part of Bayesian theory.\nFor example, we specify the following hypotheses:\n\\(H_0: \\theta \\leq 0\\) against \\(H_1: \\theta &gt; 0\\)\nThe Bayesian p-value is then \\(\\text{Bayesian p-value}=\\int_{-\\infty}^0 p(\\theta|data)d\\theta\\) where \\(p(\\theta|data)\\) denotes the posterior density."
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#predictive-inference-predicting-new-observations",
    "href": "pages/Bayesian_inference_subjective_probability.html#predictive-inference-predicting-new-observations",
    "title": "Bayesian inference and subjective probability",
    "section": "Predictive inference (predicting new observations)",
    "text": "Predictive inference (predicting new observations)\n\nPosterior predictive\nData validation (predictive performance)\nForecasting, classification, etc"
  },
  {
    "objectID": "pages/Bayesian_inference_subjective_probability.html#bayesian-vs-frequentist",
    "href": "pages/Bayesian_inference_subjective_probability.html#bayesian-vs-frequentist",
    "title": "Bayesian inference and subjective probability",
    "section": "Bayesian vs Frequentist",
    "text": "Bayesian vs Frequentist\nThis section is inspired by Efron and Hastie’s book Computer age statistical inference - algorithms, evidence, and data science\n\nBayesian inference requires a prior distribution, and the choice of prior is therefore important and sometimes challenging.\nFrequentism replaces the choice of a prior with the choice of a method or algorithm designed for the quantity of interest.\nBayesian inference answers all possible questions at once.\nFrequentism requires different methods/algorithms for different questions.\nBayesian inference is open for sequential updating, e.g. when data are to be integrated to the model over time.\n\n\nThe authors states that “Computer-age statistical inference at its most successful combines elements of the two philosophies”"
  },
  {
    "objectID": "pages/course_intro.html",
    "href": "pages/course_intro.html",
    "title": "Course introduction",
    "section": "",
    "text": "A PhD course in Bayesian analysis for participants that are not from maths\nA PhD course that brings up the link between Bayesian inference and Decision theory\nA possibility to discuss, praise and challenge Bayesian thinking\nAn introduction to Bayesian analysis to get started or get more experience\n\nBayesian analysis: Bayesian statistics, Bayesian inference, Bayesian data analysis, Bayesian modelling, Bayesian computation, Bayesian networks, Bayesian emulation, Bayesian evidence synthesis\nDecision theory: Bayesian decision theory, Bayesian hypothesis testing, Bayesian learning, decision making under uncertainty, evidence-based decision making, communicating uncertainty, uncertainty analysis in assessments, weight of evidence approaches\n\nSummer school 2015, PhD course spring 2018, PhD course online spring 2022, PhD course physical 2026\n\nBayes@Lund web page\nBayes@Lund Youtube Channel"
  },
  {
    "objectID": "pages/course_intro.html#why-this-course",
    "href": "pages/course_intro.html#why-this-course",
    "title": "Course introduction",
    "section": "",
    "text": "A PhD course in Bayesian analysis for participants that are not from maths\nA PhD course that brings up the link between Bayesian inference and Decision theory\nA possibility to discuss, praise and challenge Bayesian thinking\nAn introduction to Bayesian analysis to get started or get more experience\n\nBayesian analysis: Bayesian statistics, Bayesian inference, Bayesian data analysis, Bayesian modelling, Bayesian computation, Bayesian networks, Bayesian emulation, Bayesian evidence synthesis\nDecision theory: Bayesian decision theory, Bayesian hypothesis testing, Bayesian learning, decision making under uncertainty, evidence-based decision making, communicating uncertainty, uncertainty analysis in assessments, weight of evidence approaches\n\nSummer school 2015, PhD course spring 2018, PhD course online spring 2022, PhD course physical 2026\n\nBayes@Lund web page\nBayes@Lund Youtube Channel"
  },
  {
    "objectID": "pages/course_intro.html#goals",
    "href": "pages/course_intro.html#goals",
    "title": "Course introduction",
    "section": "Goals",
    "text": "Goals\nContent:\nBayesian analysis, Discrete Bayesian Belief Networks, Hierarchical modelling, Continuous Bayesian Belief Networks\nProbabilistic uncertainty analysis, Non-probabilistic methods for uncertainty analysis, Scientific principles to quantify uncertainty\nBayesian Decision Theory, Principles of cautious decision making"
  },
  {
    "objectID": "pages/course_intro.html#material-and-content",
    "href": "pages/course_intro.html#material-and-content",
    "title": "Course introduction",
    "section": "Material and content",
    "text": "Material and content\nTwo books\nBR - Alicia A. Johnson, Miles Ott, Mine Dogucu Bayes Rules\nDBDA - John K. Kruschke Doing Bayesian Data Analysis\nAdditional material: lecture notes and exercises available and updated during the course on this git web page"
  },
  {
    "objectID": "pages/course_intro.html#assessment",
    "href": "pages/course_intro.html#assessment",
    "title": "Course introduction",
    "section": "Assessment",
    "text": "Assessment\nAssessment is based on student activities in practical exercises and seminars, and on the written project report.\n\nPresence at the two physical meetings (let us know if you cannot attend in advance)\nActive participation in literature seminars\nCompleted individual report"
  },
  {
    "objectID": "pages/course_intro.html#literature-seminar",
    "href": "pages/course_intro.html#literature-seminar",
    "title": "Course introduction",
    "section": "Literature seminar",
    "text": "Literature seminar\n\nLearning goals\n\nDigest a Bayesian decision analysis for a concrete problem\nPractice to identify sources of uncertainty in an assessment\nBe able to give examples of principles to quantify and treat uncertainty in a Bayesian analysis\nBe able to give an account of science theoretic arguments behind principles to quantify and treat uncertainty in knowledge production and decision making\nReflect on the limitations and justification of Bayesian principles and subjective probability to produce scientific advice or decision support\nPractice collaboration and presentation in an interdisciplinary context\n\n\n\nInstructions\nThe literature seminar is constructed around three themes.\n\nBefore the seminar\n\nDownload the literature. You have been placed in a group (A-C). You are to read the three papers assigned to your group. Skim through the other papers. Look at the questions for your group.\n\nDuring the seminar\n\nTogether with your group, prepare and give a presentation of the three papers (try to keep it short &lt; 8 min per paper). Structure the presentation around the answers to the questions under that theme.\n\n\nTheme 1: The Bayesian analysis combined with decision making\nGroup A. Augustynczik, A. L. et al. Productivity of Fagus sylvatica under climate change–A Bayesian analysis of risk and uncertainty using the model 3-PG. Forest Ecology and Management 401, 192–206 (2017). link to paper\nGroup B. Spiegelhalter, D. J. & Best, N. G. Bayesian approaches to multiple sources of evidence and uncertainty in complex cost-effectiveness modelling. Statist. Med. 22, 3687–3709 (2003). link to paper\nGroup C. Theobald, C. M. & Talbot, M. The Bayesian choice of crop variety and fertilizer dose. Journal of the Royal Statistical Society: Series C (Applied Statistics) 51, 23–36 (2002). link to paper\nQuestions\n\nDescribe the decision problem! Who is the decision-maker? What are the decision alternatives? How are values/preferences defined and used? What qualifies as a good decision?\nDescribe the model to inform the decision problem. What is the quantify of interest? What type of data was used? How were priors specified?\nList sources of uncertainty for this assessment!\nDescribe strengths and weaknesses of the methods and principles underlying the paper as a method in research and as a method to produce scientific advice (decision-support).\n\n\n\nTheme 2: Uncertainty and subjective probability\nGroup A. Meder, B., Le Lec, F. & Osman, M. Decision making in uncertain times: what can cognitive and decision sciences say about or learn from economic crises? Trends in Cognitive Sciences 17, 257–260 (2013). link to paper\nGroup B. Paté-Cornell, E. On “Black Swans” and “Perfect Storms”: Risk Analysis and Management When Statistics Are Not Enough: On Black Swans and Perfect Storms. Risk Analysis 32, 1823–1833 (2012). link to paper\nGroup C. Parker, W. S. Whose probabilities? Predicting climate change with ensembles of models. Philosophy of Science 77, 985–997 (2010). link to paper\nQuestions\n\nWhat type of assessment or decision problem is used as context for the paper?\nHow is uncertainty presented or defined by the authors?\nWhat use of subjective probability is described and are there any requirements or justifications for this use?\nDo the authors suggest any limitations with subjective probability as a measure to quantify uncertainty in research and in processes that produce scientific advice? If so, which?\n\n\n\nTheme 3: Beyond the Bayesian paradigm\nGroup A. French, S. Axiomatizing the Bayesian Paradigm in Parallel Small Worlds. Operations Research (2020). link to paper\nGroup B. O’Hagan, A. & Oakley, J. E. Probability is perfect, but we can’t elicit it perfectly. Reliability Engineering & System Safety 85, 239–248 (2004). link to paper\nGroup C. Gärdenfors, Peter. & Sahlin, Nils. E. Unreliable probabilities, risk taking, and decision making. Synthese 53, 361–386 (1982). link to paper\nQuestions\n\nWhat challenges with the Bayesian paradigm are raised by the authors?\nWhat is their solution?\nDescribe strengths and weaknesses of the methods and principles proposed in the paper relevant and useful in research and in processes that produce scientific advice (decision-support)."
  },
  {
    "objectID": "pages/course_intro.html#individual-project",
    "href": "pages/course_intro.html#individual-project",
    "title": "Course introduction",
    "section": "Individual project",
    "text": "Individual project\nThe purpose of the individual project is to allow you to implement Bayesian analysis on a problem that you specify yourself. This can be something that is related to your research (but it doesn’t have to be). Select a problem making sure that the amount of work should not exceed more than a week.\nThe problem should be either a Bayesian analysis with an informed and justified prior or a Decision analysis supported by a Bayesian analysis\n\nShare your project idea\nGet early feedback from Ullrika/Zheng\nPerform the project\nProduce a minimal report (project description, what you did, result)\nGet feedback from Ullrika/Zheng\nThe project should preferably be finalised within a month after the last course day. Instructions to submit will follow\n\nIf you are new to Bayesian stuff - MAKE IT SIMPLE!\nIf you feel advanced - take the opportunity to try something new"
  },
  {
    "objectID": "pages/course_intro.html#practical-things",
    "href": "pages/course_intro.html#practical-things",
    "title": "Course introduction",
    "section": "Practical things",
    "text": "Practical things\nLADOK - contact your ladok-administrator with a request to be registered to the course with identity 6FNAM001.\nWe will issue certificates upon a completed course.\nPUB after the course today"
  },
  {
    "objectID": "pages/exercise_1.html",
    "href": "pages/exercise_1.html",
    "title": "Probability",
    "section": "",
    "text": "Background\nThere are different interpretations and uses of probability.\nProbability as a mathematical measure is agnostic to the interpretation, i.e. the laws of probability are the same.\n\n\nPurpose\n\nTo understand common interpretations of probability and for what they are used\n\n\n\nContent\n\nExperiment to illustrate the frequency interpretation of probability\nTheoretical probability vs Expected frequency\nSubjective probability\n\n\n\nReferences\nI have used examples and text from the book Teaching probability by Jenny Gage and David Spiegelhalter from 2016, Cambridge University Press.\n\n\nFrequency\nThe experiment is setup as follows:\n\nAssign one student to flip the symmetric coin. You can flip the Antoninus Pius - Bronze Sestertius - Roman Empire using the virtual coin flipper on random.org\nRecord if the outcome is heads or tails.\nAssign another student to throw a six sided dice using the virtual dice roller on random.org\nRecord if the outcome is a number in the range 1 to 5 or a six\nRepeat \\(N=5\\) times\n\nRecord the outcomes in a table\nAnswer the following question:\n\nWhat is the observed frequency of the event “heads followed by a six”?\n\n\n\nExpected frequency\nDiscuss:\n\nIs this a reliable estimate of the expected frequency? If not, what can one do to make it more reliable?\nWhat do you expect the frequency to be if \\(N\\) would be a very large number?\n\n\n\n\n\n\n\nTip\n\n\n\nDefine the events A = “heads” and B = “six”.\nSpecify P(A) and P(B).\nCalculate P(A and B) using the multiplication rule for two independent events.\nDon’t forget to multiply by \\(N\\) to get the expected frequency.\n\n\nRepeat the experiment with \\(N = 100\\) to see what happens when the number of observations grow.\n\n\nChance\nNow let us go back to the step where you specified the probabilities P(A) and P(B). How did you do that? One way to do it is to look at the outcome space, find the outcomes that correspond to the event and divide by the total number of outcomes.\nFor the coin the outcome space is “heads” and “tails”, i.e. n = 2. The event of a getting “heads” can occur in one of the outcomes, i.e. m = 1. Under the assumption that all outcomes are equally likely, the theoretical probability for “heads” is \\(\\frac{m}{n} = \\frac{1}{2}\\).\nFor the dice, the outcome space is 1, 2, 3, 4, 5, and 6, i.e. n = 6. The event of getting a “six” can occur in one way, i.e. m = 1. The theoretical probability for the event “six” is therefore \\(\\frac{1}{6}\\).\n\n\n\n\n\n\nNote\n\n\n\nNotice that theoretical probabilities can only be used in balanced situations such as dice, cards, or lottery tickets where it justified to assume symmetry (equal probability) for all possible outcomes.\n\n\n\n\nRelative frequency\nIf we divide the frequency of an event by the number of trials \\(N\\), we get the relative frequency which is a good estimate of a probability for the event to occur at the next iteration of the same experiment.\nLet \\(m\\) be the number of times the event has occurred. \\(E(\\frac{m}{N})=\\frac{E(m)}{N}=\\frac{N\\cdot P(event)}{N} = P(event)\\)\nRelative frequencies can be used to estimate the probability for an event as long as the observations are equally likely across the full outcome space.\n\n\n\n\n\n\nMake sure N is large\n\n\n\nThe more observations (i.e. larger N) the better estimate.\nThe more extreme event, i.e. very low or high probability of occurring, the more observations are needed.\nBe very skeptical to estimates of probabilities that are either 0 and 1, when the event is possible to occur.\n\n\n\n\nBelief (Personal probability)\nTake one of the thumbtacks provided in the exercise and a cup. Put the thumbtack in the cup, shake and place the cup upside down on a table without revealing the outcome.\n\nWhat outcomes are possible?\n\nFocus on the outcome that the thumbtack in the cup is having its head down with the needle pointing upwards.\n\nLet everyone in the group write down their personal probability of this event as a number between 0 and 1, where 0 means that it is impossible to occur and 1 means that it is certain to occur. Write down first without revealing it to the others, and then share!\n\n\n\n\n\n\n\nCromwell’s rule\n\n\n\nProbabilities 1 (“the event will definitely occur”) or 0 (“the event will definitely not occur”) should be avoided, except when applied to statements that are logically true or false.\n\n\n\nDiscuss if and why the personal probabilities differ in the group\n\nThis is an example of probability as a subjective probability that is purely a personal judgement based on available evidence and assumptions.\nMore evidence ought to result in smaller divergence in judgements. One way to illustrate this is to make some tosses of the thumbtack and let everyone revise their judgement.\n\nDo that!\n\nGiven that the evidence is revealing the outcome, the subjective probabilities held by the students in the group should now be either 1 or 0.\nIn reality, we seldom have such full certainty as in this example. Probabilities are almost inevitably based on judgements and assumptions e.g. about a data generating process.\n\n\n\n\n\n\nA general advice\n\n\n\nProbability can be thought of as an expected frequency. Instead of saying that “the probability of the event is 0.20 (or 20%)”, you can say “out of 100 situations like this, we would expect the event to occur 20 times”.\nBy carefully stating the denominator (reference class), ambiguity about the meaning of probability can be avoided.\nThis advice applies to any of the interpretations.\n\n\n\n\nBelief about a unique event\n\nHow certain are you that it will rain in Lundagård during Lundakarnevalen in May this year?\n\n\n\nBelief about a unique number\nDon’t google this before making your judgement!\n\nWhat is the number of tigers in India?"
  },
  {
    "objectID": "pages/exercise_3.html",
    "href": "pages/exercise_3.html",
    "title": "Write your own MCMC sampler",
    "section": "",
    "text": "Background\nMCMC-sampling is an important part of contemporary Bayesian analysis. The participants of this course have different backgrounds, with varying experience of MCMC-sampling. The purpose of this exercise is to let everyone practice in specifying and coding up an MCMC sampler. We are not asking for an advanced model to sample from.\n\n\nTask\n\nSelect a Bayesian model (likelihood and prior) with a limited number of parameters (1 or 2) and data (few data points). If you struggle coming up with a model, you can use the coin-flip example (see below).\nSet up a Metropolis-Hastings algorithm to sample from the posterior\nImplement it in code and run it\nVisualise the MCMC-sampling\nRun it with different choices of priors - from flat to specific\n\n\n\nCoin flip\nYou have a coin and believe it is fair with equal chance to get head or tail. To test your belief, you flipped it for 100 times and got 55 heads and 45 tails.\n\nWrite your Bayesian model including a beta prior and a binomial likelihood\nderive the analytical solution- a conjugate posterior.\nCode a Metropolis algorithm to get the posterior for the parameters.\n\nTips: proposes new values for the probability of heads, calculates the acceptance ratio based on the Beta prior and Binomial likelihood, and records the resulting chain, generate a traceplot.\n\nVisualise your sampling steps and summarize your posterior distribution.\nCompare with the analytical solution.\nUpdate the Metropolis algorithm script so that it reflect the following prior: the coin is heavily biased towards heads.\n\n\n\nCoding demonstration for the coin flip example\nCoin flip R script"
  },
  {
    "objectID": "pages/MCMC.html",
    "href": "pages/MCMC.html",
    "title": "MCMC-sampling",
    "section": "",
    "text": "describe what is a Markov chain monte carlo (MCMC)\ndescribe the purpose and applicability range of MCMC\ncompare the strength and weakness of MCMC with other posterior estimation methods\ndevelop a simple MCMC (complete exercise 3)\ndescribe MCMC diagnostics"
  },
  {
    "objectID": "pages/MCMC.html#learning-goals",
    "href": "pages/MCMC.html#learning-goals",
    "title": "MCMC-sampling",
    "section": "",
    "text": "describe what is a Markov chain monte carlo (MCMC)\ndescribe the purpose and applicability range of MCMC\ncompare the strength and weakness of MCMC with other posterior estimation methods\ndevelop a simple MCMC (complete exercise 3)\ndescribe MCMC diagnostics"
  },
  {
    "objectID": "pages/MCMC.html#beta-binomial-conjugation",
    "href": "pages/MCMC.html#beta-binomial-conjugation",
    "title": "MCMC-sampling",
    "section": "Beta-binomial conjugation",
    "text": "Beta-binomial conjugation\nBinomial likelihood:\nn Bernoulli trials with y successes and unknown probability of success \\(\\theta\\).\n\\[\n\\text{Binomial}(n, y,\\theta)\n\\]\nThe prior is a beta distribution:\n\\[\nBeta(\\alpha, \\beta)\n\\]\nConjugation: the posterior distribution is also a beta distribution:\n\\[\n  Beta(\\alpha + y, \\beta + n - y)\n\\]"
  },
  {
    "objectID": "pages/MCMC.html#posterior-computation",
    "href": "pages/MCMC.html#posterior-computation",
    "title": "MCMC-sampling",
    "section": "Posterior computation",
    "text": "Posterior computation\n\nAnalytical solution: conjugation often impossible\nGrid approximation: possible but efficiency drops exponentialy with dimension\nLaPlace approximation: assumption of multivariate normality often not applicable\nMarkov Chain Monte Carlo (MCMC): flexible, efficient"
  },
  {
    "objectID": "pages/MCMC.html#what-is-mcmc",
    "href": "pages/MCMC.html#what-is-mcmc",
    "title": "MCMC-sampling",
    "section": "What is MCMC",
    "text": "What is MCMC\n\nMarkov chain\n\nMarkov process: \\(f(t+1)=g(f(t),noise)\\)\nChain\n\nMonte Carlo: a large number of samples can approximate the distribution\n\nMCMC transforms the question:\nFROM:\nGetting the posterior distribution\nTO\nGetting enough representative samples from the posterior distribution"
  },
  {
    "objectID": "pages/MCMC.html#example-island-hopping",
    "href": "pages/MCMC.html#example-island-hopping",
    "title": "MCMC-sampling",
    "section": "Example: Island hopping",
    "text": "Example: Island hopping\n\nMake a proposal.\nAcceptance ratio \\(p_{prop}=\\frac{poposal}{current}\\).\nIf \\(p_{prop}\\) &gt; 1, move; if \\(p_{prop}\\)=1, stay.\nIf \\(p_{prop}\\) &lt; 1, generate a random value k between (0,1). If \\(k&lt;p_{prop}\\), then move.\nrepeat 1-4.\n\n\nSimulate the hopping process\nNumber of islands (parameter values) unknown in reality.\n\n\n\n\n\n\n\n\n\nLet’s first compute the posterior manually.\nPrior: no knowledge of the islands\n\nprior_function &lt;- function(island) {\n  return(1/num_island)  # Uniform prior\n}\n\nLikelihood: proportional to relative population of each island\n\nlikelihood_function &lt;- function(island) {\n  return(island / sum(1:num_island))  # Proportional to island size\n}\n\nTherefore, posterior = prior * likelihood / marginals\n\ntrue_posterior &lt;- sapply(1:num_island, function(i) {\n  prior_function(i) * likelihood_function(i)\n})\ntrue_posterior &lt;- true_posterior / sum(true_posterior)  # marginalize\nnames(true_posterior) &lt;- paste0(\"Island \",1:num_island)\ntrue_posterior\n\n  Island 1   Island 2   Island 3   Island 4   Island 5 \n0.06666667 0.13333333 0.20000000 0.26666667 0.33333333 \n\n\nNow compute the posterior with MCMC\n\nnum_iterations &lt;- 1e3\nstarting_island &lt;- 3\n\n# store the positions\nchain &lt;- numeric(num_iterations)\nprior_values &lt;- numeric(num_iterations)\nlikelihood_values &lt;- numeric(num_iterations)\nposterior_values &lt;- numeric(num_iterations)\n\n# Calculate values for initial position\nchain[1] &lt;- starting_island\nprior_values[1] &lt;- prior_function(chain[1])\nlikelihood_values[1] &lt;- likelihood_function(chain[1])\nposterior_values[1] &lt;- prior_values[1] * likelihood_values[1]  # Unnormalized posterior\n\n# Store jump decisions for analysis\naccepted &lt;- logical(num_iterations - 1)\nacceptance_ratios &lt;- numeric(num_iterations - 1)\n\nfor(i in 2:num_iterations){\n    current &lt;- chain[i-1]\n    \n    # Propose a move: randomly jump to an adjacent island\n    jump &lt;- sample(c(-1,1), 1)  \n    proposed &lt;- current + jump\n    # Handle boundaries with wrap-around\n    if (proposed &lt; 1) proposed &lt;- num_island\n    if (proposed &gt; num_island) proposed &lt;- 1\n    # random walk proposal\n    # proposed &lt;- current + rnorm(1,proposal_mean,proposal_sd)\n    \n    # compute acceptance ratio\n    # current position\n    prior_current &lt;- prior_function(current)\n    likelihood_current &lt;- likelihood_function(current)\n    posterior_current &lt;- prior_current * likelihood_current  # Unnormalized\n\n    # proposed position    \n    prior_proposed &lt;- prior_function(proposed)\n    likelihood_proposed &lt;- likelihood_function(proposed)\n    posterior_proposed &lt;- prior_proposed * likelihood_proposed  # Unnormalized\n\n    acceptance_ratio &lt;- posterior_proposed / posterior_current\n    acceptance_prob &lt;- min(1, acceptance_ratio)\n\n    # Store the computed values\n    prior_values[i-1] &lt;- prior_current\n    likelihood_values[i-1] &lt;- likelihood_current\n    posterior_values[i-1] &lt;- posterior_current\n    acceptance_ratios[i-1] &lt;- acceptance_prob\n\n    # decide the jump\n    if (runif(1) &lt; acceptance_prob) {\n      chain[i] &lt;- proposed\n      accepted[i-1] &lt;- TRUE\n    } else {\n      chain[i] &lt;- current\n      accepted[i-1] &lt;- FALSE\n    }\n}\n\nNow summarize the results from MCMC\n\nprior_values[num_iterations] &lt;- prior_function(chain[num_iterations])\nlikelihood_values[num_iterations] &lt;- likelihood_function(chain[num_iterations])\nposterior_values[num_iterations] &lt;- prior_values[num_iterations] * likelihood_values[num_iterations]\n\n# Calculate empirical frequencies from MCMC samples\nmcmc_freq &lt;- table(chain) / num_iterations\nmcmc_df &lt;- data.frame(\n  island = 1:num_island,\n  mcmc_prob = as.numeric(mcmc_freq),\n  true_posterior = true_posterior\n)\nmcmc_df\n\n         island mcmc_prob true_posterior\nIsland 1      1     0.064     0.06666667\nIsland 2      2     0.121     0.13333333\nIsland 3      3     0.187     0.20000000\nIsland 4      4     0.269     0.26666667\nIsland 5      5     0.359     0.33333333\n\n\nTrace the move\n\n# Trace plot with acceptance indicators\ntrace_df &lt;- data.frame(\n  iteration = 1:num_iterations,\n  island = chain,\n  accepted = c(NA, accepted),\n  posterior = posterior_values\n)\np_trace &lt;- ggplot(trace_df, aes(x = iteration, y = island)) +\n  geom_line(alpha = 0.5) +\n  geom_point(aes( size = posterior), alpha = 0.7) +\n  # scale_color_manual(values = c(\"FALSE\" = \"red\", \"TRUE\" = \"green\"), \n  #                    na.value = \"black\", name = \"Accepted\") +\n  scale_size_continuous(name = \"Posterior\", range = c(1, 3)) +\n  scale_y_continuous(breaks = 1:num_island, limits = c(1, num_island)) +\n  theme_classic() +\n  labs(title = \"Trace Plot\",\n       subtitle = \"Point size proportional to posterior probability\",\n       x = \"Iteration\",\n       y = \"Island Number\")\np_trace\n\n\n\n\n\n\n\n\n\n\nSummary of hopping\nWhen repeated enough times, frequency on any island matches the relative population of the island.\nThree critical things:\n\nknown your position and adjacent options\nmaking a proposal and knowing the population of the proposal\nknowing the population of the current, to calculate the acceptance ratio \\(p_{prop}=\\frac{proposal}{current}\\)."
  },
  {
    "objectID": "pages/MCMC.html#metropolis-algorithm",
    "href": "pages/MCMC.html#metropolis-algorithm",
    "title": "MCMC-sampling",
    "section": "Metropolis algorithm",
    "text": "Metropolis algorithm\n\nIsland hopping is a special case, Metropolis algorithm could handle:\n\ncontinuous positions\nmore than one dimension\ncomplex proposals\n\n\\[\ny=\\beta_0 + \\beta_1 x + \\epsilon\n\\]\nModel:\n\\[\n\\begin{equation}\n\\begin{split}\n\\epsilon \\sim N(0,\\sigma^2) \\\\\ny \\sim N(\\beta_0 + \\beta_1 x, \\epsilon)\n\\end{split}\n\\end{equation}\n\\]\n\\(\\beta_0, \\beta_1\\) are parameters\nLikelihood:\n\\[\np(Y|\\beta_0,\\beta_1,\\epsilon,x)=\\prod_i^{n} \\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp(-\\frac{(y-(\\beta_0+\\beta_1 x))^2}{2\\sigma^2})\n\\]\nPriors:\n\\(\\beta_0 \\sim N(0,5)\\).\nHow does the island hopping analogy work here?\n\n\n\n\n\n\nMetropolis algorithm\n\n\n\n\nStart with an arbitrary initial value of the parameter, and denote it \\(\\theta_{current}\\)\nRandomly generate a proposed jump, \\(\\Delta\\theta \\sim N(0,\\sigma^2)\\) and derive the proposed parameter as \\(\\theta_{proposed} = \\theta_{current}+\\Delta\\theta\\).\nCompute the probability of moving to the proposed value as \\[\\begin{split} & \\\\ p_{move}=min\\left(1,\\frac{f(\\theta_{proposed}|y)}{f(\\theta_{current}|y)}\\right) =& \\\\min\\left(1,\\frac{l(y|\\theta_{proposed})f(\\theta_{proposed})}{l(y|\\theta_{current})f(\\theta_{current})}\\right) \\end{split}\\]\nAccept the proposed parameter value if a random value sampled from a [0,1] uniform distribution is less than \\(p_{move}\\)\n\nRepeat steps 1 to 3 until a sufficiently representative sample of the posterior has been generated.\nThrow away a burn-in period of the sampling and keep the part where the algorithm has converged.\nThe Metropolis algorithm (is a type of importance sampling) which can be combined with ways to generate proposals make the sampling more efficient, including Gibbs sampling and Hamiltonian Markov Chain (HMC)."
  },
  {
    "objectID": "pages/MCMC.html#mcmc-diagnostics",
    "href": "pages/MCMC.html#mcmc-diagnostics",
    "title": "MCMC-sampling",
    "section": "MCMC diagnostics",
    "text": "MCMC diagnostics\nBefore accepting MCMC results, how good they are?\n\nTrace plot: biased by the arbitrary starting value? fully explore the posterior range?\nRhat/ Gelman-Rubins statistics: convergence of multiple chains, also shown in the trace plot\nEffective sample size: measures chain accuracy- how many independent sampling steps for the chain to approximate the posterior\nAutocorrelation: also shows chain accuracy- strong correlation between steps that are one or two steps apart breaks Markov process\n\nRead the Bayes rule book chapter 6.3 and DBDA chapter 7.5 for technical details and examples."
  },
  {
    "objectID": "pages/solution_exercise_2.html",
    "href": "pages/solution_exercise_2.html",
    "title": "Conjugate models",
    "section": "",
    "text": "library(ggplot2)\n\n\nTask 1\nTest an hypothesis using conjugate model. How sensitive is the conclusion from the choice of prior?\nLet \\(\\lambda\\) be the average number of goals scored in a Women’s World Cup game. We’ll analyse \\(\\lambda\\) by a Gamma-Poisson model where data \\(Y_i\\) is the observed number of goals scored in a sample of World Cup games\n\nSpecify the model\nPlot and summarize our prior understanding of \\(\\lambda\\).\nWhy is the Poisson model a reasonable choice for our data\n\\(Y_i\\)?\n\nUse the wwc_2019_matches data from fivethirtyeight\nThe wwc_2019_matches data includes the number of goals scored by the two teams in each 2019 Women’s World Cup match. We summed the scores by the two teams per game, made a histogram and calculated some summary statistics:\n\n\nSome larger datasets need to be installed separately, like senators and\nhouse_district_forecast. To install these, we recommend you install the\nfivethirtyeightdata package by running:\ninstall.packages('fivethirtyeightdata', repos =\n'https://fivethirtyeightdata.github.io/drat/', type = 'source')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   2.000   3.000   2.808   3.000  13.000 \n\n\n[1] 52\n\n\n\nMake a test if the average number of goals scored in a Women’s World Cup game is less than 1.8.\n\n\n# Summary statistics of data\nm &lt;- mean(goals)\nn &lt;- length(goals)\n\n# Prior \n\n## Flat\ns_prior = 1 #shape\nr_prior = 1/2 #rate\n#expected value is shape/rate\ns_prior/r_prior\n\n[1] 2\n\n#variance increase with shape and decrease with rate\ns_prior/r_prior^2\n\n[1] 4\n\n## Strong\ns_prior = 1*20\nr_prior = 1/2*20\n#expected value is shape/rate. \ns_prior/r_prior \n\n[1] 2\n\n#variance increase with shape and decrease with rate\ns_prior/r_prior^2\n\n[1] 0.2\n\n# Posterior\ns_post = s_prior + m*n #shape\nr_post = r_prior + n #rate\n\n\npp &lt;- ppoints(200)\n#yy &lt;- seq(0.01,10,by=0.01)\nyy &lt;- qgamma(pp,shape=s_prior,rate=r_prior)\ndf &lt;- data.frame(goals=c(yy,yy),\n           pdf=c(dgamma(yy,shape=s_prior,rate=r_prior),dgamma(yy,shape=s_post,rate=r_post)),\n           dist=rep(c(\"prior\",\"post\"),each=200))\n\nggplot(df,aes(x=goals,y=pdf,col=dist)) +\n  geom_line() +\n  annotate(geom=\"point\",x=m,y=0) +\n  geom_vline(xintercept=1.8)\n\n\n\n\n\n\n\n\n\n# test if lambda is less than 1.8\n\n# I calculate the probability that lambda is less than 1.8 using the posterior. If this value is not super small, I will consider it to \npgamma(1.8,shape=s_post,rate=r_post)\n\n[1] 9.125193e-07\n\n# 95% probability interval \nc(qgamma(0.025,shape=s_post,rate=r_post),\nqgamma(0.975,shape=s_post,rate=r_post))\n\n[1] 2.285608 3.099771\n\n\n\n\nTask 2\nUse conjugate models to construct probability intervals for the results from a clinical trial and compare to a published meta-analysis.\nLancet paper\n\nA relative risk (RR) is a ratio of the probability of an event occurring in the exposed group versus the probability of the event occurring in the non-exposed group.\n\nReproduce the probability interval for a RR from the forest plots tables e.g. Scales et al 2003\nCalculate a probability interval for one of the studies for which the RR is not calculable, e.g. Hall et al 2014\n\n\n# data Scales\ny_mask = 3\nN_mask = 16\ny_nomask = 4\nN_nomask = 15\n\nif(FALSE){\n# not calculable Hall\ny_mask = 0\nN_mask = 42\ny_nomask = 0\nN_nomask = 6\n}\n\n\n# prior\na_prior = 1\nb_prior = 1\n\n# posterior\na_mask = a_prior + y_mask\nb_mask = b_prior + N_mask - y_mask\na_nomask = a_prior + y_nomask\nb_nomask = b_prior + N_nomask - y_nomask\n\n\npp = ppoints(200)\ndf &lt;- data.frame(theta=pp,pdf=c(dbeta(pp,a_mask,b_mask),dbeta(pp,a_nomask,b_nomask)),treatment=rep(c(\"mask\",\"no mask\"),each=200))\n\nggplot(df,aes(x=theta,y=pdf,col=treatment))+\n  geom_line()\n\n\n\n\n\n\n\n\n\n# sample to calculate posterior for the derived quantity RR\nniter = 10^4\n\nRR = rbeta(niter,a_mask,b_mask)/rbeta(niter,a_nomask,b_nomask)\n\n# summarise the posterior for RR - a value less than 1 is in favour of wearing face masks\n\nmean(RR) # posterior mean\n\n[1] 0.8938533\n\nquantile(RR,probs=c(0.025,0.975)) # posterior 95% probability interval\n\n     2.5%     97.5% \n0.2051107 2.4558359"
  }
]